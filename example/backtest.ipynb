{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HOJm-eFdqGra",
        "ygmdTx7Qul3n"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhHQ3AiRiar3"
      },
      "outputs": [],
      "source": [
        "_ = !pip install python-binance\n",
        "_ = !pip install --upgrade gupload\n",
        "_ = !pip install ta # Library for Technical Analysis\n",
        "_ = !pip install pytictoc\n",
        "_ = !pip install yfinance\n",
        "_ = !pip install -q -U keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glMOHCFjif1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOJm-eFdqGra"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miUHDU0vo4Fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1792daa6-2b5c-4d41-f6cb-59dee2375778"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# IMPORTS\n",
        "import pandas as pd\n",
        "import math\n",
        "import os.path\n",
        "import time\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "# from bitmex import bitmex\n",
        "from binance.client import Client\n",
        "from datetime import timedelta, datetime\n",
        "from dateutil import parser\n",
        "from tqdm import tqdm_notebook #(Optional, used for progress-bars)\n",
        "\n",
        "# save to google drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import auth\n",
        "from google.colab import drive\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from numpy.polynomial.polynomial import polyfit\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "import warnings\n",
        "from pytictoc import TicToc\n",
        "t = TicToc() #create instance of class\n",
        "\n",
        "# TA package for technical indicator\n",
        "import ta as ta\n",
        "from ta import add_all_ta_features\n",
        "from ta.utils import dropna\n",
        "\n",
        "# Scipy\n",
        "import scipy\n",
        "from scipy.signal import argrelmin, argrelmax\n",
        "from scipy.signal import savgol_filter\n",
        "\n",
        "# Keras / Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, Input, Conv1D, MaxPooling1D, Flatten, GRU, Dropout, Bidirectional, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from time import time\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras import backend as K\n",
        "\n",
        "#Sklearn\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, MinMaxScaler, QuantileTransformer, OneHotEncoder\n",
        "#from sklearn.metrics import classification_report, precision_recall_curve, plot_precision_recall_curve\n",
        "\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "# fix seed for all random function\n",
        "\n",
        "# seed_value = 42 # seed for all random function\n",
        "# os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "# random.seed(seed_value)\n",
        "# np.random.seed(seed_value)\n",
        "# tf.random.set_seed(seed_value)\n",
        "\n",
        "\n",
        "# Configure a new global `tensorflow` session\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "tf.config.experimental.enable_op_determinism()\n",
        "tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "seed_value = 42 # seed for all random function\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "tf.keras.utils.set_random_seed(0) \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5cOiL5YRjWF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygmdTx7Qul3n"
      },
      "source": [
        "# Trade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z26PtxadvPnC"
      },
      "outputs": [],
      "source": [
        "def trade_by_model(temp, start_m=100, hold=0):\n",
        "  m = start_m\n",
        "  count_buy = 0\n",
        "  count_sell = 0\n",
        "  for index, row in temp.iterrows():\n",
        "    status_buy = 0\n",
        "    status_sell = 0\n",
        "\n",
        "    # if row['sum_p'] >= 3: \n",
        "    #   status_buy = 1\n",
        "    # elif row['sum_n'] < 3:\n",
        "    #   status_sell = 1\n",
        "    if row['predict_1'] > 0:\n",
        "      status_buy = 1\n",
        "    elif row['predict_1'] < 0:\n",
        "      status_sell = 1\n",
        "\n",
        "    # if (row['smoothed_return_close_predict_n1'] > 0) & (row['smoothed_return_close_predict_n2'] > 0) & (row['smoothed_return_close_predict_n3'] > 0):\n",
        "    #   status_buy = 1\n",
        "    # elif (row['smoothed_return_close_predict_n1'] < 0) & (row['smoothed_return_close_predict_n2'] < 0) & (row['smoothed_return_close_predict_n3'] < 0):\n",
        "    #   status_sell = 1\n",
        "\n",
        "    if status_buy == 1:\n",
        "      if hold == 1:\n",
        "        pass\n",
        "      else:\n",
        "        count_buy = count_buy + 1\n",
        "        temp.loc[index:]['buy'] = 1\n",
        "        temp['buy'] = np.where(temp['Time']==row['Time'],1,temp['buy'])\n",
        "        current_price = row['Close']\n",
        "        hold = 1\n",
        "        \n",
        "\n",
        "    if status_sell == 1:\n",
        "      if hold == 0:\n",
        "        pass\n",
        "      else:\n",
        "        count_sell = count_sell +1\n",
        "        temp.loc[index:]['sell'] = 1\n",
        "        temp['sell'] = np.where(temp['Time']==row['Time'],1,temp['sell'])\n",
        "        m = (row['Close']/current_price)*m\n",
        "        hold = 0\n",
        "\n",
        "    temp['port'] = np.where(temp['Time']==row['Time'],m,temp['port'])\n",
        "    temp['hold'] = np.where(temp['Time']==row['Time'],hold,temp['hold'])\n",
        "  # print(count_buy)\n",
        "  # print(count_sell)\n",
        "  return ((m-start_m)/start_m)*100, temp, m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br4CX9Deukbn"
      },
      "outputs": [],
      "source": [
        "class Portfolio:\n",
        "    def __init__(self, initial_capital = 1000):\n",
        "        self.portfolio = {}\n",
        "        self.cash = initial_capital\n",
        "        self.max_port_value = initial_capital\n",
        "        self.max_port_value_time = pd.Timedelta(0)\n",
        "    \n",
        "    # position\n",
        "    def add_position(self, position,  # position = 'long' or 'short'\n",
        "                     open_time, open_price, open_value):\n",
        "        # check cash\n",
        "        if self.cash < open_value:\n",
        "          print('ERROR - can afford lesser amount')\n",
        "          open_value = self.cash\n",
        "          if open_value == 0:\n",
        "            print('ERROR - cannot afford')\n",
        "            return\n",
        "\n",
        "        # check opposite position\n",
        "        if position == 'long' and self.is_position('short'):\n",
        "          print('ERROR - caanot open long position while there is exposure of short position')\n",
        "        elif position == 'short' and self.is_position('long'):\n",
        "          print('ERROR - caanot open short position while there is exposure of long position')\n",
        "\n",
        "        self.cash -= open_value\n",
        "        self.portfolio[open_time] = Trade(position, open_price, open_value)\n",
        "\n",
        "    \n",
        "    def close_position(self, position, close_size, close_price, close_time, trd_fee_frac, hld_fee_frac_hr):\n",
        "        \n",
        "        close_trade_list = []\n",
        "        while close_size > 0:\n",
        "          # Find open time to close (FIFO)\n",
        "          if len(self.portfolio.items()) > 0:\n",
        "            open_time = min([key for key, value in self.portfolio.items()])\n",
        "          else:\n",
        "            print('ERROR - No opening position to close')\n",
        "\n",
        "          # Close whole trade\n",
        "          if close_size >= self.portfolio[open_time].size:\n",
        "            # find size to close\n",
        "            trade_close_size = self.portfolio[open_time].size\n",
        "          # Close part of trade\n",
        "          else:\n",
        "            # find size to close\n",
        "            trade_close_size = close_size\n",
        "            \n",
        "          # to correct negative price\n",
        "          close_price = max(0, close_price)\n",
        "          \n",
        "          close_trade_summary, open_value, PnL = self.portfolio[open_time].close(trade_close_size, close_price, close_time, open_time, trd_fee_frac, hld_fee_frac_hr)\n",
        "\n",
        "          # update port\n",
        "          close_size -= trade_close_size\n",
        "          if position == 'long':\n",
        "            self.cash += open_value + PnL # trade_close_size * close_price\n",
        "          elif position == 'short':\n",
        "            self.cash += open_value + PnL # trade_close_size * (self.portfolio[open_time].open_price * 2 - close_price)\n",
        "\n",
        "          close_trade_summary.append(self.cash)\n",
        "          close_trade_summary.append(self.get_total_opening_value())\n",
        "          \n",
        "\n",
        "          # delete trade\n",
        "          if self.portfolio[open_time].size <= 0: \n",
        "            del self.portfolio[open_time]\n",
        "          \n",
        "          # append trand summary\n",
        "          close_trade_list.append(close_trade_summary)\n",
        "          \n",
        "        return close_trade_list\n",
        "      \n",
        "    def get_total_opening_value(self):\n",
        "        return sum([value.open_price * value.size for key, value in self.portfolio.items()])\n",
        "      \n",
        "\n",
        "    def is_position(self, position):\n",
        "        return self.get_size(position) > 0\n",
        "\n",
        "    def update(self, close, high, low, time, trd_fee_frac, hld_fee_frac_hr):\n",
        "\n",
        "        # update stat of all trade\n",
        "        self.update_trade_stat(close, high, low, time, trd_fee_frac, hld_fee_frac_hr)\n",
        "\n",
        "        # get port value\n",
        "        port_value = self.get_total_unrealized_trade_value() + self.cash\n",
        "\n",
        "        # to correct negative price\n",
        "        port_value = max(0, port_value)\n",
        "\n",
        "        if port_value >= self.max_port_value:\n",
        "          self.max_port_value = port_value\n",
        "          self.max_port_value_time = time\n",
        "        \n",
        "        dd = min((port_value - self.max_port_value) / self.max_port_value, 0)\n",
        "        dd_dur = time - self.max_port_value_time\n",
        "\n",
        "        port_size = self.get_total_size()\n",
        "        return [time, port_value, port_size, dd, dd_dur]\n",
        "\n",
        "    def get_total_unrealized_trade_value(self):\n",
        "        return sum([trade.value for key, trade in self.portfolio.items()])\n",
        "\n",
        "    def update_trade_stat(self, close, high, low, time, trd_fee_frac, hld_fee_frac_hr):\n",
        "        for k, trade in self.portfolio.items():\n",
        "            trade.update_stat(k, close, high, low, time, trd_fee_frac, hld_fee_frac_hr)\n",
        "\n",
        "    def get_total_size(self):\n",
        "        long_size = self.get_size('long')\n",
        "        short_size = self.get_size('short')\n",
        "        return long_size - short_size\n",
        "\n",
        "    def get_size(self, position):\n",
        "        return sum([value.size for key, value in self.portfolio.items() if value.position == position])\n",
        "\n",
        "class Trade:\n",
        "    def __init__(self, position, open_price, open_value):\n",
        "        \n",
        "        self.position = position\n",
        "        self.open_price = open_price\n",
        "        self.price = open_price\n",
        "        self.value = open_value\n",
        "        self.size = open_value / open_price\n",
        "        self.maxDD = 0\n",
        "\n",
        "\n",
        "    def close(self, trade_close_size, close_price, close_time, open_time, trd_fee_frac, hld_fee_frac_hr):\n",
        "        \n",
        "        trade_close_size = trade_close_size\n",
        "        open_price = self.open_price\n",
        "        close_value = close_price * trade_close_size\n",
        "        open_value = open_price * trade_close_size\n",
        "        trd_fee = trd_fee_frac * (open_value + close_value)\n",
        "        trd_fee = 0\n",
        "        hld_dur = close_time - open_time\n",
        "        hld_dur_hr = (hld_dur).total_seconds() / 3600\n",
        "        hld_fee = hld_fee_frac_hr * hld_dur_hr * (open_value + close_value)/2\n",
        "\n",
        "        if self.position == 'long':\n",
        "          PnL = close_value - open_value - trd_fee - hld_fee\n",
        "        elif self.position == 'short':\n",
        "          PnL = open_value - close_value - trd_fee - hld_fee\n",
        "        \n",
        "        maxDD = self.maxDD\n",
        "        return_frac = PnL / open_value\n",
        "\n",
        "        win = True if return_frac > 0 else False\n",
        "\n",
        "\n",
        "        # update trade\n",
        "        self.size = self.size - trade_close_size \n",
        "        return [self.position, open_time, close_time, open_price, close_price, trade_close_size, hld_dur, trd_fee, hld_fee, PnL, maxDD, return_frac, win], \\\n",
        "                open_value, PnL\n",
        "\n",
        "    def update_stat(self, open_time, close, high, low, time, trd_fee_frac, hld_fee_frac_hr):\n",
        "        self.price = close\n",
        "        current_value = close * self.size\n",
        "        open_value = self.open_price * self.size\n",
        "        trd_fee = trd_fee_frac * open_value # trd_fee_frac * (open_value + current_value)\n",
        "        hld_dur_hr = (time - open_time).total_seconds() / 3600\n",
        "        hld_fee = hld_fee_frac_hr * hld_dur_hr * (open_value + current_value)/2\n",
        "        \n",
        "        if self.position == 'long':\n",
        "          PnL = current_value - open_value - trd_fee - hld_fee\n",
        "\n",
        "        elif self.position == 'short':\n",
        "          PnL = open_value - current_value - trd_fee - hld_fee\n",
        "        \n",
        "        self.value = open_value + PnL # trade value\n",
        "        self.maxDD = min(PnL / open_value, self.maxDD)\n",
        "\n",
        "def Backtest(df, start, end, col_name = None, initial_capital = 100, \n",
        "             trd_fee_frac = 0.000, hld_fee_frac_hr = 0# 2.5e-05 # hld_fee_frac_hr = 2.5e-05 = 0.02 %/8hr\n",
        "             ):\n",
        "  if col_name == None: col_name = ['Open', 'High', 'Low', 'Close', 'Long_Position', 'Short_Position', 'Long_Price', 'Short_Price']\n",
        "\n",
        "  df = df.rename(columns={col_name[0]: 'Open',\n",
        "                          col_name[1]: 'High',\n",
        "                          col_name[2]: 'Low',\n",
        "                          col_name[3]: 'Close',\n",
        "                          col_name[4]: 'Long_Position',\n",
        "                          col_name[5]: 'Short_Position',\n",
        "                          col_name[6]: 'Long_Price',\n",
        "                          col_name[7]: 'Short_Price'})\n",
        "\n",
        "  # defind portfolio\n",
        "  PORTFOLIO = Portfolio(initial_capital = initial_capital)\n",
        "  PORTFOLIO_curve = []\n",
        "  PORTFOLIO_trades = []\n",
        "  PORTFOLIO_stats = {}\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    \n",
        "    # update portfolio curve\n",
        "    curve = PORTFOLIO.update(close = df['Close'][i], high = df['High'][i], low = df['Low'][i], \n",
        "                             time = df.index[i], trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    PORTFOLIO_curve.append(curve) \n",
        "\n",
        "    # check close position\n",
        "    if (df['Long_Position'][i] < df['Long_Position'][i-1]):\n",
        "      # close long position\n",
        "\n",
        "      # calculate fraction for close position from current size\n",
        "      close_size = ((df['Long_Position'][i-1] - df['Long_Position'][i]) / df['Long_Position'][i-1]) * PORTFOLIO.get_size('long')\n",
        "\n",
        "      # close long position\n",
        "      close_trade_list = PORTFOLIO.close_position('long', close_size = close_size, close_price = df['Long_Price'][i], close_time = df.index[i], \n",
        "                                          trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      \n",
        "\n",
        "      for j in close_trade_list:\n",
        "        PORTFOLIO_trades.append(j)\n",
        "\n",
        "    if (df['Short_Position'][i] < df['Short_Position'][i-1]):\n",
        "      # close short position\n",
        "\n",
        "      # calculate fraction for close position from current size\n",
        "      close_size = ((df['Short_Position'][i-1] - df['Short_Position'][i]) / df['Short_Position'][i-1]) * PORTFOLIO.get_size('short')\n",
        "\n",
        "      # close long position\n",
        "      close_trade_list = PORTFOLIO.close_position('short', close_size = close_size, close_price = df['Short_Price'][i], close_time = df.index[i], \n",
        "                                          trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      \n",
        "      # record all closed trades\n",
        "      for j in close_trade_list:\n",
        "        PORTFOLIO_trades.append(j)\n",
        "\n",
        "    # check open postion\n",
        "    if (i == 0 and df['Long_Position'][i] > 0) or \\\n",
        "        (df['Long_Position'][i] > df['Long_Position'][i-1]):\n",
        "      # open long position\n",
        "\n",
        "      # calculate fraction for open position from remaining cash\n",
        "      prev_long_position = df['Long_Position'][i-1] if i != 0 else 0\n",
        "      open_value = (df['Long_Position'][i] - prev_long_position) * (PORTFOLIO.cash + PORTFOLIO.get_total_opening_value())\n",
        "\n",
        "      # open long position\n",
        "      PORTFOLIO.add_position('long', open_time = df.index[i], open_price = df['Long_Price'][i], open_value = open_value)\n",
        "\n",
        "    if (i == 0 and df['Short_Position'][i] > 0) or \\\n",
        "        (df['Short_Position'][i] > df['Short_Position'][i-1]):\n",
        "      # open short position\n",
        "\n",
        "      # calculate fraction for open position from remaining cash\n",
        "      prev_short_position = df['Short_Position'][i-1] if i != 0 else 0\n",
        "      open_value = (df['Short_Position'][i] - prev_short_position) * (PORTFOLIO.cash + PORTFOLIO.get_total_opening_value())\n",
        "      \n",
        "      # open short position\n",
        "      PORTFOLIO.add_position('short', open_time = df.index[i], open_price = df['Short_Price'][i], open_value = open_value)\n",
        "\n",
        "  # portfolio stat summary\n",
        "  PORTFOLIO_stats['_curve'] = pd.DataFrame(data = PORTFOLIO_curve, columns=['timestamp', 'port_value', 'port_size', 'dd', 'dd_dur'])\n",
        "  PORTFOLIO_stats['_curve'] = PORTFOLIO_stats['_curve'].set_index('timestamp')\n",
        "  \n",
        "  PORTFOLIO_stats['_trades'] = pd.DataFrame(data = PORTFOLIO_trades, columns=['position', 'open_time', 'close_time', 'open_price', \n",
        "                                                                              'close_price', 'trade_close_size', 'hld_dur', 'trd_fee', 'hld_fee', \n",
        "                                                                              'PnL', 'maxDD', 'return_frac', 'win',\n",
        "                                                                              'remain_cash', 'total_opening_value'])\n",
        "  PORTFOLIO_stats['start'] = df.index[0]\n",
        "  PORTFOLIO_stats['end'] = df.index[-1]\n",
        "  PORTFOLIO_stats['dur'] = df.index[-1] - df.index[0]\n",
        "  PORTFOLIO_stats['init_capital'] = initial_capital\n",
        "  PORTFOLIO_stats['final_capital'] = PORTFOLIO_stats['_curve']['port_value'][-1]\n",
        "  PORTFOLIO_stats['return_frac'] = PORTFOLIO_stats['final_capital'] / PORTFOLIO_stats['init_capital'] - 1\n",
        "  PORTFOLIO_stats['return_frac_ann'] = ((1 + PORTFOLIO_stats['return_frac']) ** (365/PORTFOLIO_stats['dur'].days)) - 1\n",
        "\n",
        "  # Asset STD\n",
        "  # std_per_bar = df['Close'].pct_change().std()\n",
        "  # Port STD\n",
        "  std_per_bar = PORTFOLIO_stats['_curve']['port_value'].pct_change().std()\n",
        "  no_bar_in_yr = 1 / ((df.index[-1] - df.index[0]).days/365/df.shape[0])\n",
        "\n",
        "  PORTFOLIO_stats['volatility_ann'] = std_per_bar * (no_bar_in_yr ** 0.5)\n",
        "  if PORTFOLIO_stats['volatility_ann'] != 0:\n",
        "    PORTFOLIO_stats['sharpe_ratio_ann'] = (PORTFOLIO_stats['return_frac_ann'] - 0) / PORTFOLIO_stats['volatility_ann']\n",
        "  else:\n",
        "    PORTFOLIO_stats['sharpe_ratio_ann'] = np.nan\n",
        "  PORTFOLIO_stats['port_mdd_frac'] = min(PORTFOLIO_stats['_curve']['dd'])\n",
        "  PORTFOLIO_stats['port_mdd_dur'] = min(PORTFOLIO_stats['_curve']['dd_dur'])\n",
        "\n",
        "  # No Trade\n",
        "  if PORTFOLIO_stats['_trades'].shape[0] == 0:\n",
        "  \n",
        "    PORTFOLIO_stats['trade_mdd_frac'] = 0\n",
        "    PORTFOLIO_stats['trade_P10mdd_frac'] = 0\n",
        "    PORTFOLIO_stats['win_rate'] = 0\n",
        "    PORTFOLIO_stats['no_trades'] = 0\n",
        "    PORTFOLIO_stats['avg_hld_dur'] = pd.Timedelta(0)\n",
        "    PORTFOLIO_stats['max_hld_dur'] = pd.Timedelta(0)\n",
        "    PORTFOLIO_stats['reward_to_risk'] = 0\n",
        "    PORTFOLIO_stats['expectency_frac'] = 0\n",
        "\n",
        "  else:\n",
        "\n",
        "    PORTFOLIO_stats['trade_mdd_frac'] = min(PORTFOLIO_stats['_trades']['maxDD'])\n",
        "    PORTFOLIO_stats['trade_P10mdd_frac'] = np.percentile(PORTFOLIO_stats['_trades']['maxDD'], 10)\n",
        "    PORTFOLIO_stats['win_rate'] = PORTFOLIO_stats['_trades']['win'].sum()/PORTFOLIO_stats['_trades']['win'].count()\n",
        "    PORTFOLIO_stats['no_trades'] = PORTFOLIO_stats['_trades'].shape[0]\n",
        "    PORTFOLIO_stats['avg_hld_dur'] = PORTFOLIO_stats['_trades']['hld_dur'].mean()\n",
        "    PORTFOLIO_stats['max_hld_dur'] = PORTFOLIO_stats['_trades']['hld_dur'].max()\n",
        "    \n",
        "    reward = PORTFOLIO_stats['_trades']['PnL'][PORTFOLIO_stats['_trades']['PnL'] > 0].sum()\n",
        "    risk = abs(PORTFOLIO_stats['_trades']['PnL'][PORTFOLIO_stats['_trades']['PnL'] < 0].sum())\n",
        "\n",
        "    if risk != 0:\n",
        "      PORTFOLIO_stats['reward_to_risk'] = reward / risk\n",
        "    elif PORTFOLIO_stats['_trades']['PnL'][PORTFOLIO_stats['_trades']['PnL'] > 0].sum() > 0:\n",
        "      PORTFOLIO_stats['reward_to_risk'] = np.inf\n",
        "    else:\n",
        "      PORTFOLIO_stats['reward_to_risk'] = 0\n",
        "    \n",
        "    PORTFOLIO_stats['expectency_frac'] = PORTFOLIO_stats['_trades']['return_frac'].mean()\n",
        "\n",
        "  # Buy & Hold ROI/ Sharpe\n",
        "  bh_std_per_bar = df['Close'].pct_change().std()\n",
        "  PORTFOLIO_stats['bh_return_frac'] = (df['Close'][-1] - df['Close'][0]) / df['Close'][0]\n",
        "  PORTFOLIO_stats['bh_return_frac_ann'] =  ((1 + PORTFOLIO_stats['bh_return_frac']) ** (365/PORTFOLIO_stats['dur'].days)) - 1\n",
        "  PORTFOLIO_stats['bh_volatility_ann'] = bh_std_per_bar * (no_bar_in_yr ** 0.5)\n",
        "  PORTFOLIO_stats['bh_sharpe_ratio_ann'] = (PORTFOLIO_stats['bh_return_frac_ann'] - 0) / PORTFOLIO_stats['bh_volatility_ann']\n",
        "\n",
        "  return PORTFOLIO_stats\n",
        "\n",
        "\n",
        "def report_summary(backtest, print_report = True, return_list = False):\n",
        "  start = backtest['start']\n",
        "  end = backtest['end']\n",
        "  dur = backtest['dur']\n",
        "  init_capital = round(backtest['init_capital'],2)\n",
        "  final_capital = round(backtest['final_capital'],2)\n",
        "  roi = round(backtest['return_frac']*100,2)\n",
        "  roi_ann = round(backtest['return_frac_ann']*100,2)\n",
        "  volatility_ann = round(backtest['volatility_ann']*100,2)\n",
        "  sharpe_ratio_ann = round(backtest['sharpe_ratio_ann'],2)\n",
        "  port_mdd = round(backtest['port_mdd_frac']*100,2)\n",
        "  trade_mdd = round(backtest['trade_mdd_frac']*100,2)\n",
        "  trade_P10_mdd = round(backtest['trade_P10mdd_frac']*100,2)\n",
        "  win_rate = round(backtest['win_rate']*100,2)\n",
        "  no_trades = backtest['no_trades']\n",
        "  avg_hld_dur = round(backtest['avg_hld_dur'].total_seconds()/3600,1)\n",
        "  max_hld_dur = round(backtest['max_hld_dur'].total_seconds()/3600,1)\n",
        "  reward_to_risk = round(backtest['reward_to_risk'],2)\n",
        "  expectency = round(backtest['expectency_frac']*100,2)\n",
        "\n",
        "\n",
        "  if print_report:\n",
        "    print('Start : \\t\\t\\t' + str(start))\n",
        "    print('End : \\t\\t\\t\\t' + str(end))\n",
        "    print('Duration : \\t\\t\\t' + str(dur))\n",
        "    print('Initial Capital : \\t\\t' + str(init_capital) + ' $')\n",
        "    print('Final Capital : \\t\\t' + str(final_capital) + ' $')\n",
        "    print('ROI : \\t\\t\\t\\t' + str(roi) + ' %')\n",
        "    print('Ann. ROI : \\t\\t\\t' + str(roi_ann) + ' %')\n",
        "    print('Ann. Volatility : \\t\\t' + str(volatility_ann) + ' %')\n",
        "    print('Ann. Sharpe Ratio : \\t\\t' + str(sharpe_ratio_ann))\n",
        "    print('Port Max. Drawdown : \\t\\t' + str(port_mdd) + ' %')\n",
        "    print('Trade Max. Drawdown : \\t\\t' + str(trade_mdd) + ' %')\n",
        "    print('Trade P10 Max. Drawdown : \\t' + str(trade_P10_mdd) + ' %')\n",
        "    print('Win Rate : \\t\\t\\t' + str(win_rate) + ' %')\n",
        "    print('No. of trades : \\t\\t' + str(no_trades) + ' times')\n",
        "    print('Avg. Holding Duration : \\t' + str(avg_hld_dur) + ' hrs.')\n",
        "    print('Max. Holding Duration : \\t' + str(max_hld_dur) + ' hrs.')\n",
        "    print('Rewards to Risk : \\t\\t' + str(reward_to_risk) + ' times')\n",
        "    print('Expectency : \\t\\t\\t' + str(expectency) + ' %')\n",
        "    print('='*60)\n",
        "    print('Buy&Hold ROI : \\t\\t\\t' + str(round(backtest['bh_return_frac']*100,2)) + ' %')\n",
        "    print('Buy&Hold Ann. ROI : \\t\\t' + str(round(backtest['bh_return_frac_ann']*100,2)) + ' %')\n",
        "    print('Buy&Hold Ann. Volatility : \\t' + str(round(backtest['bh_volatility_ann']*100,2)) + ' %')\n",
        "    print('Buy&Hold Ann. Sharpe Ratio : \\t' + str(round(backtest['bh_sharpe_ratio_ann'],2)))\n",
        "    print('='*60)\n",
        "    print()\n",
        "  \n",
        "  if return_list:\n",
        "    return [start, end, dur, init_capital, final_capital, roi, roi_ann, volatility_ann, sharpe_ratio_ann, \n",
        "            port_mdd, trade_mdd, trade_P10_mdd, win_rate, no_trades, avg_hld_dur, max_hld_dur, reward_to_risk, expectency]\n",
        "\n",
        "\n",
        "def RSI_model_results(df, date_index, initial_capital = 100):\n",
        "  df_evaluation = df[OHLC_features + targets2].copy(deep=True)\n",
        "  df_evaluation['RSI'] = ta.momentum.RSIIndicator(close=df_evaluation['Close'], window=n_ind, fillna=False).rsi()\n",
        "  df_evaluation = df_evaluation[test_date[0]:test_date[-1]]\n",
        "\n",
        "  # thrs_range = np.linspace(10, 90, 9)\n",
        "  # thrs_range_l_opn = thrs_range\n",
        "  # thrs_range_l_cls = thrs_range\n",
        "  # thrs_range_s_opn = thrs_range\n",
        "  # thrs_range_s_cls = thrs_range\n",
        "  thrs_range_l_opn = [30]\n",
        "  thrs_range_l_cls = [70]\n",
        "  thrs_range_s_opn = [70]\n",
        "  thrs_range_s_cls = [30]\n",
        "\n",
        "  # Long\n",
        "  df_thrs_l = []\n",
        "  for thrs_l_opn in thrs_range_l_opn:\n",
        "    for thrs_l_cls in thrs_range_l_cls:\n",
        "      df_evaluation_thrs = RSI_strategy(df_evaluation, thrs_l = [thrs_l_opn, thrs_l_cls], thrs_s = [np.nan, np.nan])\n",
        "      backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      df_thrs_l.append([thrs_l_opn, thrs_l_cls, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_l = pd.DataFrame(data = df_thrs_l, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "  df_thrs_l = df_thrs_l.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Short\n",
        "  df_thrs_s = []\n",
        "  for thrs_s_opn in thrs_range_s_opn:\n",
        "    for thrs_s_cls in thrs_range_s_cls:\n",
        "      df_evaluation_thrs = RSI_strategy(df_evaluation, thrs_l = [np.nan, np.nan], thrs_s = [thrs_s_opn, thrs_s_cls])\n",
        "      backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      df_thrs_s.append([np.nan, np.nan, thrs_s_opn, thrs_s_cls] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_s = pd.DataFrame(data = df_thrs_s, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "\n",
        "  df_thrs_s = df_thrs_s.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # # Backtest report\n",
        "  thrs_report = {'backtest_opt_l': {'thrs_l':[df_thrs_l['thrs_l_opn'][0], df_thrs_l['thrs_l_cls'][0]], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_opt_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[df_thrs_s['thrs_s_opn'][0], df_thrs_s['thrs_s_cls'][0]]},\n",
        "                 'backtest_0_l': {'thrs_l':[30, 70], 'thrs_s':[np.nan, np.nan]}, # normal trigger point for RSI strategy = 30/70\n",
        "                 'backtest_0_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[70, 30]} # normal trigger point for RSI strategy = 30/70\n",
        "                }\n",
        "\n",
        "  backtest_result = {}\n",
        "  df_backtest_result = []\n",
        "\n",
        "  for k, v in thrs_report.items():\n",
        "    df_evaluation_thrs = RSI_strategy(df_evaluation, thrs_l = [v['thrs_l'][0], v['thrs_l'][1]], thrs_s = [v['thrs_s'][0], v['thrs_s'][1]])\n",
        "    backtest_evaluation = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    backtest_result[k] = {'df': df_evaluation_thrs.copy(deep=True),\n",
        "                          'backtest': backtest_evaluation.copy()}\n",
        "    df_backtest_result.append([k] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_backtest_result = pd.DataFrame(data = df_backtest_result, columns=['name', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "  return df_thrs_l, df_thrs_s, backtest_result, df_backtest_result\n",
        "\n",
        "\n",
        "# create strategy\n",
        "def RSI_strategy(df,  thrs_l = [0, 0], # [Open (>=) , Close (<=)]\n",
        "                             thrs_s = [0, 0], signal = 'RSI'):   # [Open (<=) , Close (>=)]\n",
        "  df['thrs_l_opn'] = thrs_l[0]\n",
        "  df['thrs_l_cls'] = thrs_l[1]\n",
        "  df['thrs_s_opn'] = thrs_s[0]\n",
        "  df['thrs_s_cls'] = thrs_s[1]\n",
        "\n",
        "  df['Long_Position'] = np.nan\n",
        "  df['Long_Price'] = np.nan\n",
        "  df['Short_Position'] = np.nan\n",
        "  df['Short_Price'] = np.nan\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    idx = df.index[i]\n",
        "    # long position =======\n",
        "    if i == 0: \n",
        "      df.loc[idx, 'Long_Position'] = 0\n",
        "      pass\n",
        "\n",
        "    elif df[signal][i-1] < df['thrs_l_opn'][i] and df[signal][i] >= df['thrs_l_opn'][i]: # smooth return pass thrs upward\n",
        "      # trigger open long position\n",
        "      df.loc[idx, 'Long_Position'] = 1\n",
        "      df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "\n",
        "    elif (df[signal][i-1] > df['thrs_l_cls'][i] and df[signal][i] <= df['thrs_l_cls'][i]) or i == len(df) - 1: # smooth return pass thrs downward\n",
        "      # trigger close long position \n",
        "      df.loc[idx, 'Long_Position'] = 0\n",
        "      df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "    \n",
        "    else:\n",
        "      # do nothing (continue last position)\n",
        "      df.loc[idx, 'Long_Position'] = df['Long_Position'][i-1]\n",
        "\n",
        "\n",
        "    # short position =======\n",
        "    if i == 0: \n",
        "      df.loc[idx, 'Short_Position'] = 0\n",
        "\n",
        "    elif df[signal][i-1] > df['thrs_s_opn'][i] and df[signal][i] <= df['thrs_s_opn'][i]: # smooth return pass thrs downward\n",
        "      # trigger open short position\n",
        "      df.loc[idx, 'Short_Position'] = 1\n",
        "      df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "\n",
        "    elif (df[signal][i-1] < df['thrs_s_cls'][i] and df[signal][i] >= df['thrs_s_cls'][i]) or i == len(df) - 1: # smooth return pass thrs upward\n",
        "      # trigger close short position \n",
        "      df.loc[idx, 'Short_Position'] = 0\n",
        "      df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "    \n",
        "    else:\n",
        "      # do nothing (continue last position)\n",
        "      df.loc[idx, 'Short_Position'] = df['Short_Position'][i-1]\n",
        "\n",
        "  return df\n",
        "\n",
        "def RSI_report_plot(df, backtest):\n",
        "  # Plot Graph\n",
        "\n",
        "  fig,a =  plt.subplots(3, 1, figsize=(16,9), gridspec_kw={'height_ratios': [1, 2, 1]})\n",
        "\n",
        "  # Section 1) port curve ==========================\n",
        "  lns1 = a[0].plot(backtest['_curve']['port_value'], label='Port. value')\n",
        "  a[0].set_ylim(backtest['_curve']['port_value'].min()*0.8,backtest['_curve']['port_value'].max()*1.1)\n",
        "  a02 = a[0].twinx()\n",
        "  lns2 = a02.plot(backtest['_curve']['port_size'], label='Asset Exposure', color='r', linewidth=0.5)\n",
        "  # a02.set_ylim(min(0, backtest['_curve']['port_size'].min()),backtest['_curve']['port_size'].max())\n",
        "  a02.grid(False)\n",
        "  lns = lns1 + lns2\n",
        "  labs = [l.get_label() for l in lns]\n",
        "  a[0].legend(lns, labs, bbox_to_anchor=(1.15, 1))\n",
        "\n",
        "  # Section 2) asset price curve =======================\n",
        "  df['Open_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) < df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Close_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) > df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Open_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) < df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  df['Close_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) > df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  if df['Long_Position'][0] > 0: df['Open_Long_Price'][0] = df['Long_Price'][0]\n",
        "  if df['Short_Position'][0] > 0: df['Open_Short_Price'][0] = df['Shprt_Price'][0] \n",
        "\n",
        "  a[1].plot(df['Close'], label='Actual', linewidth=0.5)\n",
        "  a[1].plot(df['Smoothed_Price*'], label='Smoothed_Price*')  \n",
        "  \n",
        "  if not df['Open_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Long_Price'], c='green', label='Open_Long_Price')  \n",
        "  if not df['Close_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Long_Price'], c='red', label='Close_Long_Price')  \n",
        "  if not df['Open_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Short_Price'], c='red', label='Open_Short_Price', marker='x')  \n",
        "  if not df['Close_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Short_Price'], c='green', label='Close_Short_Price', marker='x')\n",
        "\n",
        "  a[1].legend(bbox_to_anchor=(1.15, 1))\n",
        "  a[1].set_ylim(df['Low'].min()*0.9,df['High'].max()*1.1)\n",
        "\n",
        "  # Section 3) indicator curve =============================\n",
        "  a[2].plot(df['RSI'], label='RSI')\n",
        "  if not df['thrs_l_opn'].isnull().all():\n",
        "    a[2].plot(df['thrs_l_opn'], label='thrs_l_opn', linewidth=0.5, c='green')\n",
        "  if not df['thrs_l_cls'].isnull().all():\n",
        "    a[2].plot(df['thrs_l_cls'], label='thrs_l_cls', linewidth=0.5, c='red')\n",
        "  if not df['thrs_s_opn'].isnull().all():\n",
        "    a[2].plot(df['thrs_s_opn'], label='thrs_s_opn', linewidth=0.5, c='red', linestyle=(0, (10,3)))\n",
        "  if not df['thrs_s_cls'].isnull().all():\n",
        "    a[2].plot(df['thrs_s_cls'], label='thrs_s_cls', linewidth=0.5, c='green', linestyle=(0, (10,3)))\n",
        "  a[2].legend(bbox_to_anchor=(1, 1))\n",
        "\n",
        "  plt.show()\n",
        "  print()\n",
        "\n",
        "def RSI_report_summary_plot(df, backtest):\n",
        "  report_summary(backtest, print_report = True, return_list = False)\n",
        "  RSI_report_plot(df, backtest)\n",
        "\n",
        "def BH_model_results(df, date_index, initial_capital = 100):\n",
        "  df_evaluation = df[OHLC_features + targets2].copy(deep=True)\n",
        "  df_evaluation = df_evaluation[test_date[0]:test_date[-1]]\n",
        "\n",
        "  # Long\n",
        "  df_thrs_l = []\n",
        "  df_evaluation_thrs = BH_strategy(df_evaluation, position = ['long'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_l.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_l = pd.DataFrame(data = df_thrs_l, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "  df_thrs_l = df_thrs_l.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Short\n",
        "  df_thrs_s = []\n",
        "  df_evaluation_thrs = BH_strategy(df_evaluation, position = ['short'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_s.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_s = pd.DataFrame(data = df_thrs_s, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "\n",
        "  df_thrs_s = df_thrs_s.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Backtest report\n",
        "  thrs_report = {'backtest_opt_l': {'thrs_l':[df_thrs_l['thrs_l_opn'][0], df_thrs_l['thrs_l_cls'][0]], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_opt_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[df_thrs_s['thrs_s_opn'][0], df_thrs_s['thrs_s_cls'][0]]},\n",
        "                 'backtest_0_l': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_0_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]}\n",
        "                }\n",
        "\n",
        "  backtest_result = {}\n",
        "  df_backtest_result = []\n",
        "\n",
        "  for k, v in thrs_report.items():\n",
        "    if k in ['backtest_opt_l', 'backtest_0_l']:\n",
        "      position = ['long']\n",
        "    elif k in ['backtest_opt_s', 'backtest_0_s']:\n",
        "      position = ['short']\n",
        "    \n",
        "    df_evaluation_thrs = BH_strategy(df_evaluation, position = position)\n",
        "    backtest_evaluation = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    backtest_result[k] = {'df': df_evaluation_thrs.copy(deep=True),\n",
        "                          'backtest': backtest_evaluation.copy()}\n",
        "    df_backtest_result.append([k] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_backtest_result = pd.DataFrame(data = df_backtest_result, columns=['name', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "  return df_thrs_l, df_thrs_s, backtest_result, df_backtest_result\n",
        "\n",
        "\n",
        "# create strategy\n",
        "def BH_strategy(df, position = ['long']): # position = ['long'], ['short'], ['long', 'short']\n",
        "\n",
        "  df['Long_Position'] = np.nan\n",
        "  df['Long_Price'] = np.nan\n",
        "  df['Short_Position'] = np.nan\n",
        "  df['Short_Price'] = np.nan\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    idx = df.index[i]\n",
        "    # long position =======\n",
        "    if 'long' in position:\n",
        "      if i == 0: \n",
        "        # trigger open long position\n",
        "        df.loc[idx, 'Long_Position'] = 1\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "      \n",
        "      elif i == len(df) - 1:\n",
        "        # trigger close long position \n",
        "        df.loc[idx, 'Long_Position'] = 0\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "      \n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Long_Position'] = df['Long_Position'][i-1]\n",
        "\n",
        "\n",
        "    # short position =======\n",
        "    if 'short' in position:\n",
        "      if i == 0: \n",
        "        # trigger open short position\n",
        "        df.loc[idx, 'Short_Position'] = 1\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "      \n",
        "      elif i == len(df) - 1:\n",
        "        # trigger close short position \n",
        "        df.loc[idx, 'Short_Position'] = 0\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "\n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Short_Position'] = df['Short_Position'][i-1]\n",
        "\n",
        "  return df\n",
        "\n",
        "def BH_report_plot(df, backtest):\n",
        "  # Plot Graph\n",
        "\n",
        "  fig,a =  plt.subplots(2, 1, figsize=(16,9), gridspec_kw={'height_ratios': [1, 2]})\n",
        "\n",
        "  # Section 1) port curve ==========================\n",
        "  lns1 = a[0].plot(backtest['_curve']['port_value'], label='Port. value')\n",
        "  a[0].set_ylim(backtest['_curve']['port_value'].min()*0.8,backtest['_curve']['port_value'].max()*1.1)\n",
        "  a02 = a[0].twinx()\n",
        "  lns2 = a02.plot(backtest['_curve']['port_size'], label='Asset Exposure', color='r', linewidth=0.5)\n",
        "  # a02.set_ylim(min(0, backtest['_curve']['port_size'].min()),backtest['_curve']['port_size'].max())\n",
        "  a02.grid(False)\n",
        "  lns = lns1 + lns2\n",
        "  labs = [l.get_label() for l in lns]\n",
        "  a[0].legend(lns, labs, bbox_to_anchor=(1.15, 1))\n",
        "\n",
        "  # Section 2) asset price curve =======================\n",
        "  df['Open_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) < df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Close_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) > df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Open_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) < df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  df['Close_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) > df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  if df['Long_Position'][0] > 0: df['Open_Long_Price'][0] = df['Long_Price'][0]\n",
        "  if df['Short_Position'][0] > 0: df['Open_Short_Price'][0] = df['Shprt_Price'][0] \n",
        "\n",
        "  a[1].plot(df['Close'], label='Actual', linewidth=0.5)\n",
        "  a[1].plot(df['Smoothed_Price*'], label='Smoothed_Price*')  \n",
        "  \n",
        "  if not df['Open_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Long_Price'], c='green', label='Open_Long_Price')  \n",
        "  if not df['Close_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Long_Price'], c='red', label='Close_Long_Price')  \n",
        "  if not df['Open_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Short_Price'], c='red', label='Open_Short_Price', marker='x')  \n",
        "  if not df['Close_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Short_Price'], c='green', label='Close_Short_Price', marker='x')\n",
        "\n",
        "  a[1].legend(bbox_to_anchor=(1.15, 1))\n",
        "  a[1].set_ylim(df['Low'].min()*0.9,df['High'].max()*1.1)\n",
        "\n",
        "  # # Section 3) indicator curve =============================\n",
        "  # a[2].plot(df['MACD'], label='MACD')\n",
        "  # a[2].plot(df['MACD_signal'], label='MACD_signal')\n",
        "  # a[2].legend(bbox_to_anchor=(1, 1))\n",
        "\n",
        "  plt.show()\n",
        "  print()\n",
        "\n",
        "def BH_report_summary_plot(df, backtest):\n",
        "  report_summary(backtest, print_report = True, return_list = False)\n",
        "  BH_report_plot(df, backtest)\n",
        "\n",
        "def MACD_model_results(df, date_index, initial_capital = 100):\n",
        "  df_evaluation = df[OHLC_features + targets2].copy(deep=True)\n",
        "  df_evaluation['MACD'] = ta.trend.MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False).macd()\n",
        "  df_evaluation['MACD_signal'] = ta.trend.MACD(close=df['Close'], window_slow=26, window_fast=12, window_sign=9, fillna=False).macd_signal()\n",
        "  df_evaluation = df_evaluation[test_date[0]:test_date[-1]]\n",
        "\n",
        "  # Long\n",
        "  df_thrs_l = []\n",
        "  df_evaluation_thrs = MACD_strategy(df_evaluation, position = ['long'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_l.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_l = pd.DataFrame(data = df_thrs_l, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "  df_thrs_l = df_thrs_l.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Short\n",
        "  df_thrs_s = []\n",
        "  df_evaluation_thrs = MACD_strategy(df_evaluation, position = ['short'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_s.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_s = pd.DataFrame(data = df_thrs_s, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "\n",
        "  df_thrs_s = df_thrs_s.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Backtest report\n",
        "  thrs_report = {'backtest_opt_l': {'thrs_l':[df_thrs_l['thrs_l_opn'][0], df_thrs_l['thrs_l_cls'][0]], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_opt_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[df_thrs_s['thrs_s_opn'][0], df_thrs_s['thrs_s_cls'][0]]},\n",
        "                 'backtest_0_l': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_0_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]}\n",
        "                }\n",
        "\n",
        "  backtest_result = {}\n",
        "  df_backtest_result = []\n",
        "\n",
        "  for k, v in thrs_report.items():\n",
        "    if k in ['backtest_opt_l', 'backtest_0_l']:\n",
        "      position = ['long']\n",
        "    elif k in ['backtest_opt_s', 'backtest_0_s']:\n",
        "      position = ['short']\n",
        "    \n",
        "    df_evaluation_thrs = MACD_strategy(df_evaluation, position = position)\n",
        "    backtest_evaluation = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    backtest_result[k] = {'df': df_evaluation_thrs.copy(deep=True),\n",
        "                          'backtest': backtest_evaluation.copy()}\n",
        "    df_backtest_result.append([k] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_backtest_result = pd.DataFrame(data = df_backtest_result, columns=['name', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "  return df_thrs_l, df_thrs_s, backtest_result, df_backtest_result\n",
        "\n",
        "# create strategy\n",
        "def MACD_strategy(df, position = ['long'], signal = 'MACD', signal2 = 'MACD_signal'): # position = ['long'], ['short'], ['long', 'short']\n",
        "\n",
        "  df['Long_Position'] = np.nan\n",
        "  df['Long_Price'] = np.nan\n",
        "  df['Short_Position'] = np.nan\n",
        "  df['Short_Price'] = np.nan\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    idx = df.index[i]\n",
        "    # long position =======\n",
        "    if 'long' in position:\n",
        "      if i == 0: \n",
        "        df.loc[idx, 'Long_Position'] = 0\n",
        "        pass\n",
        "\n",
        "      elif df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]: # MACD cross MACD_signal upward\n",
        "        # trigger open long position\n",
        "        df.loc[idx, 'Long_Position'] = 1\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "\n",
        "      elif (df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]) or i == len(df) - 1: # MACD cross MACD_signal downward\n",
        "        # trigger close long position \n",
        "        df.loc[idx, 'Long_Position'] = 0\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "      \n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Long_Position'] = df['Long_Position'][i-1]\n",
        "\n",
        "\n",
        "    # short position =======\n",
        "    if 'short' in position:\n",
        "      if i == 0: \n",
        "        df.loc[idx, 'Short_Position'] = 0\n",
        "\n",
        "      elif df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]: # MACD cross MACD_signal downward\n",
        "        # trigger open short position\n",
        "        df.loc[idx, 'Short_Position'] = 1\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "\n",
        "      elif (df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]) or i == len(df) - 1: # MACD cross MACD_signal upward\n",
        "        # trigger close short position \n",
        "        df.loc[idx, 'Short_Position'] = 0\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "      \n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Short_Position'] = df['Short_Position'][i-1]\n",
        "\n",
        "  return df\n",
        "\n",
        "def MACD_report_plot(df, backtest):\n",
        "  # Plot Graph\n",
        "\n",
        "  fig,a =  plt.subplots(3, 1, figsize=(16,9), gridspec_kw={'height_ratios': [1, 2, 1]})\n",
        "\n",
        "  # Section 1) port curve ==========================\n",
        "  lns1 = a[0].plot(backtest['_curve']['port_value'], label='Port. value')\n",
        "  a[0].set_ylim(backtest['_curve']['port_value'].min()*0.8,backtest['_curve']['port_value'].max()*1.1)\n",
        "  a02 = a[0].twinx()\n",
        "  lns2 = a02.plot(backtest['_curve']['port_size'], label='Asset Exposure', color='r', linewidth=0.5)\n",
        "  # a02.set_ylim(min(0, backtest['_curve']['port_size'].min()),backtest['_curve']['port_size'].max())\n",
        "  a02.grid(False)\n",
        "  lns = lns1 + lns2\n",
        "  labs = [l.get_label() for l in lns]\n",
        "  a[0].legend(lns, labs, bbox_to_anchor=(1.15, 1))\n",
        "\n",
        "  # Section 2) asset price curve =======================\n",
        "  df['Open_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) < df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Close_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) > df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Open_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) < df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  df['Close_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) > df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  if df['Long_Position'][0] > 0: df['Open_Long_Price'][0] = df['Long_Price'][0]\n",
        "  if df['Short_Position'][0] > 0: df['Open_Short_Price'][0] = df['Shprt_Price'][0] \n",
        "\n",
        "  a[1].plot(df['Close'], label='Actual', linewidth=0.5)\n",
        "  a[1].plot(df['Smoothed_Price*'], label='Smoothed_Price*')  \n",
        "  \n",
        "  if not df['Open_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Long_Price'], c='green', label='Open_Long_Price')  \n",
        "  if not df['Close_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Long_Price'], c='red', label='Close_Long_Price')  \n",
        "  if not df['Open_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Short_Price'], c='red', label='Open_Short_Price', marker='x')  \n",
        "  if not df['Close_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Short_Price'], c='green', label='Close_Short_Price', marker='x')\n",
        "\n",
        "  a[1].legend(bbox_to_anchor=(1.15, 1))\n",
        "  a[1].set_ylim(df['Low'].min()*0.9,df['High'].max()*1.1)\n",
        "\n",
        "  # Section 3) indicator curve =============================\n",
        "  a[2].plot(df['MACD'], label='MACD')\n",
        "  a[2].plot(df['MACD_signal'], label='MACD_signal')\n",
        "  a[2].legend(bbox_to_anchor=(1, 1))\n",
        "\n",
        "  plt.show()\n",
        "  print()\n",
        "\n",
        "def MACD_report_summary_plot(df, backtest):\n",
        "  report_summary(backtest, print_report = True, return_list = False)\n",
        "  MACD_report_plot(df, backtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkCWfYVVvMBq"
      },
      "outputs": [],
      "source": [
        "symbols = 'CL=F'\n",
        "# Available kline size \"1m\", \"5m\", \"15m\", \"1h\", \"4h\", \"1d\" for binance\n",
        "kline_size = '30m'\n",
        "trd_fee_pct = 0.0 # trading fee in percent\n",
        "trd_fee_frac = trd_fee_pct/100\n",
        "hld_fee_pct_8hr = 0 # holding fee in percent / 8hr (normal rate in Binance Future = 0.02%)\n",
        "hld_fee_frac_hr = hld_fee_pct_8hr/(8*100)\n",
        "OHLC_features = ['Open', 'High', 'Low', 'Close']\n",
        "price_features = ['Close', 'Volume', 'Rel_Open', 'Rel_High', 'Rel_Low']\n",
        "ind_features = ['Rel_SMA_fast', 'Rel_SMA_slow', 'MACD', 'ADX', 'CCI', 'ROC', 'RSI', 'TSI', '%K', '%D', '%R', 'Rel_BB_hband', 'Rel_BB_lband', 'Rel_ATR', 'UI',   'CMF', 'FI', 'MFI', 'VPT', 'VWAP']\n",
        "#'ADI', 'OBV' ,'MFI', 'VPT', 'VWAP'\n",
        "# time_features = ['Hour_of_Day', 'Day_of_Week', 'Day_of_Month', 'Day_of_Year']\n",
        "time_features = ['Day_of_Week', 'Day_of_Month', 'Day_of_Year']\n",
        "trans_time_features = [f(x) for x in time_features for f in (lambda x: x + '_Sin',lambda x: x + '_Cos')]\n",
        "features = price_features + trans_time_features + ind_features\n",
        "targets_scale = ['label']\n",
        "targets_not_scale = []\n",
        "targets = targets_scale + targets_not_scale\n",
        "targets2 = ['label_1',\n",
        "            ] # usd only for evaluation ploting\n",
        "rolling_indicator = False\n",
        "\n",
        "# model_no: 1 = CNN_LSTM, 2 = CNN, 3 = LSTM, 4 = LSTM_CNN, 5 = Transformer\n",
        "model_no = 4\n",
        "test_year = 2018\n",
        "case_no = 1\n",
        "cnn_no_node_list = [64, 128]\n",
        "lstm_no_node_list = [64, 128]\n",
        "model_name_dict = {1:'CNN-LSTM', 2:'CNN', 3:'LSTM', 4:'LSTM-CNN', 5:'Transformer'}\n",
        "time_beg_dict = {2015:'2005-01-01 00:00:00', 2016:'2006-01-01 00:00:00', 2017:'2007-01-01 00:00:00', 2018:'2008-01-01 00:00:00', 2019:'2009-01-01 00:00:00', 2020:'2010-01-01 00:00:00' }\n",
        "time_end_dict = {2015:'2016-01-01 00:00:00', 2016:'2017-01-01 00:00:00', 2017:'2018-01-01 00:00:00', 2018:'2019-01-01 00:00:00', 2019:'2020-01-01 00:00:00', 2020:'2021-01-01 00:00:00' }\n",
        "val_beg_dict = {2015:'2014-01-01 00:00:00', 2016:'2015-01-01 00:00:00', 2017:'2016-01-01 00:00:00', 2018:'2017-01-01 00:00:00', 2019:'2018-01-01 00:00:00', 2020:'2019-01-01 00:00:00' }\n",
        "test_beg_dict = {2015:'2015-01-01 00:00:00', 2016:'2016-01-01 00:00:00', 2017:'2017-01-01 00:00:00', 2018:'2018-01-01 00:00:00', 2019:'2019-01-01 00:00:00', 2020:'2020-01-01 00:00:00' }\n",
        "\n",
        "\n",
        "# path\n",
        "data_path = '/content/gdrive/MyDrive/2022/Data/'\n",
        "model_path = '/content/gdrive/MyDrive/2022/Model/'\n",
        "model_filename = model_path + symbols + '-' + kline_size + '/' + str(test_year) + '/' + str(case_no) + '/' + model_name_dict[model_no]\n",
        "variable_path = model_filename + '/pre-process-variables/'\n",
        "variable_filename = variable_path + 'objs.pkl'\n",
        "\n",
        "\n",
        "# Train / Val / Test Split ======================================\n",
        "split_type = 'time' # 'fraction', 'time'\n",
        "# time_beg = '2007-01-01 00:00:00' # time begin for train-val-test\n",
        "# time_end = '2018-01-01 00:00:00' # time end for train-val-test\n",
        "time_beg = time_beg_dict[test_year]\n",
        "time_end = time_end_dict[test_year]\n",
        "# for split_type = 'fraction'\n",
        "val_fraction = 0.1\n",
        "test_fraction = 0.1\n",
        "train_fraction = 1 - val_fraction - test_fraction\n",
        "# for split_type = 'time'\n",
        "val_beg = val_beg_dict[test_year]\n",
        "test_beg = test_beg_dict[test_year]\n",
        "\n",
        "T =32 # T-days window of input data for predicting target_class\n",
        "n_ind = 10 # indicator fast\n",
        "k_ind = 15 # indicator slow\n",
        "start_index_delta = - T - k_ind - 23 # import more bar befor time_beg for labeling\n",
        "end_index_delta = 2 # import more bar after time_end for labeling\n",
        "\n",
        "# Pre-procession features\n",
        "pct_change_transform_features = ['Close', 'Volume', ] # non-stationary feasture that need to transform to stationary (transform be percent change from previous time-step)\n",
        "quantile_transform_features = ['Volume', 'VPT'] # Transform feature with obviuos outliner\n",
        "# quantile_transform_features = ['Volume']\n",
        "\n",
        "\n",
        "train_model_ = True\n",
        "features_plotting = False\n",
        "save_model_ = True\n",
        "load_model_ = not train_model_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwhlszQi2gFF"
      },
      "source": [
        "## - SMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1lc28SU02kC0"
      },
      "outputs": [],
      "source": [
        "def SMA_model_results(df, date_index, initial_capital = 100):\n",
        "  df_evaluation = df[OHLC_features + targets2].copy(deep=True)\n",
        "  df_evaluation['SMA_15'] = ta.trend.SMAIndicator(close=df['Close'], window=15, fillna=False).sma_indicator()\n",
        "  df_evaluation['SMA_50'] = ta.trend.SMAIndicator(close=df['Close'], window=50, fillna=False).sma_indicator()\n",
        "  df_evaluation = df_evaluation[test_date[0]:test_date[-1]]\n",
        "\n",
        "  # Long\n",
        "  df_thrs_l = []\n",
        "  df_evaluation_thrs = SMA_strategy(df_evaluation, position = ['long'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_l.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_l = pd.DataFrame(data = df_thrs_l, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "  df_thrs_l = df_thrs_l.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Short\n",
        "  df_thrs_s = []\n",
        "  df_evaluation_thrs = SMA_strategy(df_evaluation, position = ['short'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_s.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_s = pd.DataFrame(data = df_thrs_s, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "\n",
        "  df_thrs_s = df_thrs_s.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Backtest report\n",
        "  thrs_report = {'backtest_opt_l': {'thrs_l':[df_thrs_l['thrs_l_opn'][0], df_thrs_l['thrs_l_cls'][0]], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_opt_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[df_thrs_s['thrs_s_opn'][0], df_thrs_s['thrs_s_cls'][0]]},\n",
        "                 'backtest_0_l': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_0_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]}\n",
        "                }\n",
        "\n",
        "  backtest_result = {}\n",
        "  df_backtest_result = []\n",
        "\n",
        "  for k, v in thrs_report.items():\n",
        "    if k in ['backtest_opt_l', 'backtest_0_l']:\n",
        "      position = ['long']\n",
        "    elif k in ['backtest_opt_s', 'backtest_0_s']:\n",
        "      position = ['short']\n",
        "    \n",
        "    df_evaluation_thrs = SMA_strategy(df_evaluation, position = position)\n",
        "    backtest_evaluation = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    backtest_result[k] = {'df': df_evaluation_thrs.copy(deep=True),\n",
        "                          'backtest': backtest_evaluation.copy()}\n",
        "    df_backtest_result.append([k] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_backtest_result = pd.DataFrame(data = df_backtest_result, columns=['name', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "  return df_thrs_l, df_thrs_s, backtest_result, df_backtest_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjcr09Bk2lFZ"
      },
      "outputs": [],
      "source": [
        "# create strategy\n",
        "def SMA_strategy(df, position = ['long'], signal = 'SMA_15', signal2 = 'SMA_50'): # position = ['long'], ['short'], ['long', 'short']\n",
        "\n",
        "  df['Long_Position'] = np.nan\n",
        "  df['Long_Price'] = np.nan\n",
        "  df['Short_Position'] = np.nan\n",
        "  df['Short_Price'] = np.nan\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    idx = df.index[i]\n",
        "    # long position =======\n",
        "    if 'long' in position:\n",
        "      if i == 0: \n",
        "        df.loc[idx, 'Long_Position'] = 0\n",
        "        pass\n",
        "\n",
        "      elif df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]: # SMA50 cross SMA200 upward\n",
        "        # trigger open long position\n",
        "        df.loc[idx, 'Long_Position'] = 1\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "\n",
        "      elif (df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]) or i == len(df) - 1: # SMA50 cross SMA200 downward\n",
        "        # trigger close long position \n",
        "        df.loc[idx, 'Long_Position'] = 0\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "      \n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Long_Position'] = df['Long_Position'][i-1]\n",
        "\n",
        "\n",
        "    # short position =======\n",
        "    if 'short' in position:\n",
        "      if i == 0: \n",
        "        df.loc[idx, 'Short_Position'] = 0\n",
        "\n",
        "      elif df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]: # SMA50 cross SMA200 downward\n",
        "        # trigger open short position\n",
        "        df.loc[idx, 'Short_Position'] = 1\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "\n",
        "      elif (df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]) or i == len(df) - 1: # SMA50 cross SMA200 upward\n",
        "        # trigger close short position \n",
        "        df.loc[idx, 'Short_Position'] = 0\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "      \n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Short_Position'] = df['Short_Position'][i-1]\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LEo8rwQ2lDM"
      },
      "outputs": [],
      "source": [
        "def SMA_report_plot(df, backtest):\n",
        "  # Plot Graph\n",
        "\n",
        "  fig,a =  plt.subplots(3, 1, figsize=(16,9), gridspec_kw={'height_ratios': [1, 2, 1]})\n",
        "\n",
        "  # Section 1) port curve ==========================\n",
        "  lns1 = a[0].plot(backtest['_curve']['port_value'], label='Port. value')\n",
        "  a[0].set_ylim(backtest['_curve']['port_value'].min()*0.8,backtest['_curve']['port_value'].max()*1.1)\n",
        "  a02 = a[0].twinx()\n",
        "  lns2 = a02.plot(backtest['_curve']['port_size'], label='Asset Exposure', color='r', linewidth=0.5)\n",
        "  # a02.set_ylim(min(0, backtest['_curve']['port_size'].min()),backtest['_curve']['port_size'].max())\n",
        "  a02.grid(False)\n",
        "  lns = lns1 + lns2\n",
        "  labs = [l.get_label() for l in lns]\n",
        "  a[0].legend(lns, labs, bbox_to_anchor=(1.15, 1))\n",
        "\n",
        "  # Section 2) asset price curve =======================\n",
        "  df['Open_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) < df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Close_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) > df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Open_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) < df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  df['Close_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) > df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  if df['Long_Position'][0] > 0: df['Open_Long_Price'][0] = df['Long_Price'][0]\n",
        "  if df['Short_Position'][0] > 0: df['Open_Short_Price'][0] = df['Shprt_Price'][0] \n",
        "\n",
        "  a[1].plot(df['Close'], label='Actual', linewidth=0.5)\n",
        "  a[1].plot(df['Smoothed_Price*'], label='Smoothed_Price*')  \n",
        "  \n",
        "  if not df['Open_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Long_Price'], c='green', label='Open_Long_Price')  \n",
        "  if not df['Close_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Long_Price'], c='red', label='Close_Long_Price')  \n",
        "  if not df['Open_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Short_Price'], c='red', label='Open_Short_Price', marker='x')  \n",
        "  if not df['Close_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Short_Price'], c='green', label='Close_Short_Price', marker='x')\n",
        "\n",
        "  a[1].legend(bbox_to_anchor=(1.15, 1))\n",
        "  a[1].set_ylim(df['Low'].min()*0.9,df['High'].max()*1.1)\n",
        "\n",
        "  # Section 3) indicator curve =============================\n",
        "  a[2].plot(df['SMA_15'], label='SMA_15')\n",
        "  a[2].plot(df['SMA_50'], label='SMA_50')\n",
        "  a[2].legend(bbox_to_anchor=(1, 1))\n",
        "\n",
        "  plt.show()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kpysq0S2lBc"
      },
      "outputs": [],
      "source": [
        "def SMA_report_summary_plot(df, backtest):\n",
        "  report_summary(backtest, print_report = True, return_list = False)\n",
        "  SMA_report_plot(df, backtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHWkQitq2k-V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-ynz9u529uw"
      },
      "source": [
        "## - Stochastics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhT6jbJn28Bc"
      },
      "outputs": [],
      "source": [
        "def STO_model_results(df, date_index, initial_capital = 100):\n",
        "  df_evaluation = df[OHLC_features + targets2].copy(deep=True)\n",
        "  df_evaluation['%K'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=n_ind, smooth1=n_ind, smooth2=n_ind, fillna=False).stochrsi_k()*100\n",
        "  df_evaluation['%D'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=n_ind, smooth1=n_ind, smooth2=n_ind, fillna=False).stochrsi_d()*100\n",
        "  df_evaluation = df_evaluation[test_date[0]:test_date[-1]]\n",
        "\n",
        "  # thrs_range = np.linspace(10, 90, 9)\n",
        "  # thrs_range_l_opn = thrs_range\n",
        "  # thrs_range_l_cls = thrs_range\n",
        "  # thrs_range_s_opn = thrs_range\n",
        "  # thrs_range_s_cls = thrs_range\n",
        "  thrs_range_l_opn = [20]\n",
        "  thrs_range_l_cls = [80]\n",
        "  thrs_range_s_opn = [80]\n",
        "  thrs_range_s_cls = [20]\n",
        "\n",
        "  # Long\n",
        "  df_thrs_l = []\n",
        "  for thrs_l_opn in thrs_range_l_opn:\n",
        "    for thrs_l_cls in thrs_range_l_cls:\n",
        "      df_evaluation_thrs = STO_strategy(df_evaluation, thrs_l = [thrs_l_opn, thrs_l_cls], thrs_s = [np.nan, np.nan])\n",
        "      backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      df_thrs_l.append([thrs_l_opn, thrs_l_cls, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_l = pd.DataFrame(data = df_thrs_l, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "  df_thrs_l = df_thrs_l.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Short\n",
        "  df_thrs_s = []\n",
        "  for thrs_s_opn in thrs_range_s_opn:\n",
        "    for thrs_s_cls in thrs_range_s_cls:\n",
        "      df_evaluation_thrs = STO_strategy(df_evaluation, thrs_l = [np.nan, np.nan], thrs_s = [thrs_s_opn, thrs_s_cls])\n",
        "      backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      df_thrs_s.append([np.nan, np.nan, thrs_s_opn, thrs_s_cls] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_s = pd.DataFrame(data = df_thrs_s, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "\n",
        "  df_thrs_s = df_thrs_s.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # # Backtest report\n",
        "  thrs_report = {'backtest_opt_l': {'thrs_l':[df_thrs_l['thrs_l_opn'][0], df_thrs_l['thrs_l_cls'][0]], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_opt_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[df_thrs_s['thrs_s_opn'][0], df_thrs_s['thrs_s_cls'][0]]},\n",
        "                 'backtest_0_l': {'thrs_l':[20, 80], 'thrs_s':[np.nan, np.nan]}, # normal trigger point for STO strategy = 20/80\n",
        "                 'backtest_0_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[80, 20]} # normal trigger point for STO strategy = 20/80\n",
        "                }\n",
        "\n",
        "  backtest_result = {}\n",
        "  df_backtest_result = []\n",
        "\n",
        "  for k, v in thrs_report.items():\n",
        "    df_evaluation_thrs = STO_strategy(df_evaluation, thrs_l = [v['thrs_l'][0], v['thrs_l'][1]], thrs_s = [v['thrs_s'][0], v['thrs_s'][1]])\n",
        "    backtest_evaluation = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    backtest_result[k] = {'df': df_evaluation_thrs.copy(deep=True),\n",
        "                          'backtest': backtest_evaluation.copy()}\n",
        "    df_backtest_result.append([k] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_backtest_result = pd.DataFrame(data = df_backtest_result, columns=['name', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "  return df_thrs_l, df_thrs_s, backtest_result, df_backtest_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vab-KU4x3CI7"
      },
      "outputs": [],
      "source": [
        "# create strategy\n",
        "def STO_strategy(df,  thrs_l = [0, 0], # [Open (>=) , Close (<=)]\n",
        "                             thrs_s = [0, 0], signal = '%K', signal2 = '%D'):   # [Open (<=) , Close (>=)]\n",
        "  df['thrs_l_opn'] = thrs_l[0]\n",
        "  df['thrs_l_cls'] = thrs_l[1]\n",
        "  df['thrs_s_opn'] = thrs_s[0]\n",
        "  df['thrs_s_cls'] = thrs_s[1]\n",
        "\n",
        "  df['Long_Position'] = np.nan\n",
        "  df['Long_Price'] = np.nan\n",
        "  df['Short_Position'] = np.nan\n",
        "  df['Short_Price'] = np.nan\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    idx = df.index[i]\n",
        "    # long position =======\n",
        "    if i == 0: \n",
        "      df.loc[idx, 'Long_Position'] = 0\n",
        "      pass\n",
        "\n",
        "    elif df[signal2][i] <= df['thrs_l_opn'][i] and df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]: # %D <= thres , %K cross %D upward\n",
        "      # trigger open long position\n",
        "      df.loc[idx, 'Long_Position'] = 1\n",
        "      df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "\n",
        "    elif (df[signal2][i] >= df['thrs_l_cls'][i] and df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]) or i == len(df) - 1: # %D >= thres , %K cross %D downward\n",
        "      # trigger close long position \n",
        "      df.loc[idx, 'Long_Position'] = 0\n",
        "      df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "    \n",
        "    else:\n",
        "      # do nothing (continue last position)\n",
        "      df.loc[idx, 'Long_Position'] = df['Long_Position'][i-1]\n",
        "\n",
        "\n",
        "    # short position =======\n",
        "    if i == 0: \n",
        "      df.loc[idx, 'Short_Position'] = 0\n",
        "\n",
        "    elif df[signal2][i] >= df['thrs_s_cls'][i] and df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]: # %D >= thres , %K cross %D downward\n",
        "      # trigger open short position\n",
        "      df.loc[idx, 'Short_Position'] = 1\n",
        "      df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "\n",
        "    elif (df[signal2][i] <= df['thrs_s_opn'][i] and df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]) or i == len(df) - 1: # %D <= thres , %K cross %D upward\n",
        "      # trigger close short position \n",
        "      df.loc[idx, 'Short_Position'] = 0\n",
        "      df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "    \n",
        "    else:\n",
        "      # do nothing (continue last position)\n",
        "      df.loc[idx, 'Short_Position'] = df['Short_Position'][i-1]\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIwh7L2X3CLM"
      },
      "outputs": [],
      "source": [
        "def STO_report_plot(df, backtest):\n",
        "  # Plot Graph\n",
        "\n",
        "  fig,a =  plt.subplots(3, 1, figsize=(16,9), gridspec_kw={'height_ratios': [1, 2, 1]})\n",
        "\n",
        "  # Section 1) port curve ==========================\n",
        "  lns1 = a[0].plot(backtest['_curve']['port_value'], label='Port. value')\n",
        "  a[0].set_ylim(backtest['_curve']['port_value'].min()*0.8,backtest['_curve']['port_value'].max()*1.1)\n",
        "  a02 = a[0].twinx()\n",
        "  lns2 = a02.plot(backtest['_curve']['port_size'], label='Asset Exposure', color='r', linewidth=0.5)\n",
        "  # a02.set_ylim(min(0, backtest['_curve']['port_size'].min()),backtest['_curve']['port_size'].max())\n",
        "  a02.grid(False)\n",
        "  lns = lns1 + lns2\n",
        "  labs = [l.get_label() for l in lns]\n",
        "  a[0].legend(lns, labs, bbox_to_anchor=(1.15, 1))\n",
        "\n",
        "  # Section 2) asset price curve =======================\n",
        "  df['Open_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) < df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Close_Long_Price'] = np.where(df['Long_Position'].shift(periods=1) > df['Long_Position'], df['Long_Price'], np.nan)\n",
        "  df['Open_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) < df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  df['Close_Short_Price'] = np.where(df['Short_Position'].shift(periods=1) > df['Short_Position'], df['Short_Price'], np.nan)\n",
        "  if df['Long_Position'][0] > 0: df['Open_Long_Price'][0] = df['Long_Price'][0]\n",
        "  if df['Short_Position'][0] > 0: df['Open_Short_Price'][0] = df['Shprt_Price'][0] \n",
        "\n",
        "  a[1].plot(df['Close'], label='Actual', linewidth=0.5)\n",
        "  a[1].plot(df['Smoothed_Price*'], label='Smoothed_Price*')  \n",
        "  \n",
        "  if not df['Open_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Long_Price'], c='green', label='Open_Long_Price')  \n",
        "  if not df['Close_Long_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Long_Price'], c='red', label='Close_Long_Price')  \n",
        "  if not df['Open_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Open_Short_Price'], c='red', label='Open_Short_Price', marker='x')  \n",
        "  if not df['Close_Short_Price'].isnull().all():\n",
        "    a[1].scatter(df.index, df['Close_Short_Price'], c='green', label='Close_Short_Price', marker='x')\n",
        "\n",
        "  a[1].legend(bbox_to_anchor=(1.15, 1))\n",
        "  a[1].set_ylim(df['Low'].min()*0.9,df['High'].max()*1.1)\n",
        "\n",
        "  # Section 3) indicator curve =============================\n",
        "  a[2].plot(df['%K'], label='%K')\n",
        "  a[2].plot(df['%D'], label='%D')\n",
        "  if not df['thrs_l_opn'].isnull().all():\n",
        "    a[2].plot(df['thrs_l_opn'], label='thrs_l_opn', linewidth=0.5, c='green')\n",
        "  if not df['thrs_l_cls'].isnull().all():\n",
        "    a[2].plot(df['thrs_l_cls'], label='thrs_l_cls', linewidth=0.5, c='red')\n",
        "  if not df['thrs_s_opn'].isnull().all():\n",
        "    a[2].plot(df['thrs_s_opn'], label='thrs_s_opn', linewidth=0.5, c='red', linestyle=(0, (10,3)))\n",
        "  if not df['thrs_s_cls'].isnull().all():\n",
        "    a[2].plot(df['thrs_s_cls'], label='thrs_s_cls', linewidth=0.5, c='green', linestyle=(0, (10,3)))\n",
        "  a[2].legend(bbox_to_anchor=(1, 1))\n",
        "\n",
        "  plt.show()\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6T2Clm-3CNk"
      },
      "outputs": [],
      "source": [
        "def STO_report_summary_plot(df, backtest):\n",
        "  report_summary(backtest, print_report = True, return_list = False)\n",
        "  STO_report_plot(df, backtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-PRP9mX3CP1"
      },
      "outputs": [],
      "source": [
        "def SMA_model_results(df, date_index, initial_capital = 100):\n",
        "  df_evaluation = df[OHLC_features + targets2].copy(deep=True)\n",
        "  df_evaluation['SMA_15'] = ta.trend.SMAIndicator(close=df['Close'], window=15, fillna=False).sma_indicator()\n",
        "  df_evaluation['SMA_50'] = ta.trend.SMAIndicator(close=df['Close'], window=50, fillna=False).sma_indicator()\n",
        "  df_evaluation = df_evaluation[test_date[0]:test_date[-1]]\n",
        "\n",
        "  # Long\n",
        "  df_thrs_l = []\n",
        "  df_evaluation_thrs = SMA_strategy(df_evaluation, position = ['long'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_l.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_l = pd.DataFrame(data = df_thrs_l, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "  df_thrs_l = df_thrs_l.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Short\n",
        "  df_thrs_s = []\n",
        "  df_evaluation_thrs = SMA_strategy(df_evaluation, position = ['short'])\n",
        "  backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "  df_thrs_s.append([np.nan, np.nan, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_s = pd.DataFrame(data = df_thrs_s, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "\n",
        "  df_thrs_s = df_thrs_s.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Backtest report\n",
        "  thrs_report = {'backtest_opt_l': {'thrs_l':[df_thrs_l['thrs_l_opn'][0], df_thrs_l['thrs_l_cls'][0]], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_opt_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[df_thrs_s['thrs_s_opn'][0], df_thrs_s['thrs_s_cls'][0]]},\n",
        "                 'backtest_0_l': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_0_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[np.nan, np.nan]}\n",
        "                }\n",
        "\n",
        "  backtest_result = {}\n",
        "  df_backtest_result = []\n",
        "\n",
        "  for k, v in thrs_report.items():\n",
        "    if k in ['backtest_opt_l', 'backtest_0_l']:\n",
        "      position = ['long']\n",
        "    elif k in ['backtest_opt_s', 'backtest_0_s']:\n",
        "      position = ['short']\n",
        "    \n",
        "    df_evaluation_thrs = SMA_strategy(df_evaluation, position = position)\n",
        "    backtest_evaluation = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    backtest_result[k] = {'df': df_evaluation_thrs.copy(deep=True),\n",
        "                          'backtest': backtest_evaluation.copy()}\n",
        "    df_backtest_result.append([k] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_backtest_result = pd.DataFrame(data = df_backtest_result, columns=['name', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "  return df_thrs_l, df_thrs_s, backtest_result, df_backtest_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XlYN8YV3CSK"
      },
      "outputs": [],
      "source": [
        "# create strategy\n",
        "def SMA_strategy(df, position = ['long'], signal = 'SMA_15', signal2 = 'SMA_50'): # position = ['long'], ['short'], ['long', 'short']\n",
        "\n",
        "  df['Long_Position'] = np.nan\n",
        "  df['Long_Price'] = np.nan\n",
        "  df['Short_Position'] = np.nan\n",
        "  df['Short_Price'] = np.nan\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    idx = df.index[i]\n",
        "    # long position =======\n",
        "    if 'long' in position:\n",
        "      if i == 0: \n",
        "        df.loc[idx, 'Long_Position'] = 0\n",
        "        pass\n",
        "\n",
        "      elif df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]: # SMA50 cross SMA200 upward\n",
        "        # trigger open long position\n",
        "        df.loc[idx, 'Long_Position'] = 1\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "\n",
        "      elif (df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]) or i == len(df) - 1: # SMA50 cross SMA200 downward\n",
        "        # trigger close long position \n",
        "        df.loc[idx, 'Long_Position'] = 0\n",
        "        df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "      \n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Long_Position'] = df['Long_Position'][i-1]\n",
        "\n",
        "\n",
        "    # short position =======\n",
        "    if 'short' in position:\n",
        "      if i == 0: \n",
        "        df.loc[idx, 'Short_Position'] = 0\n",
        "\n",
        "      elif df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]: # SMA50 cross SMA200 downward\n",
        "        # trigger open short position\n",
        "        df.loc[idx, 'Short_Position'] = 1\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "\n",
        "      elif (df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]) or i == len(df) - 1: # SMA50 cross SMA200 upward\n",
        "        # trigger close short position \n",
        "        df.loc[idx, 'Short_Position'] = 0\n",
        "        df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "      \n",
        "      else:\n",
        "        # do nothing (continue last position)\n",
        "        df.loc[idx, 'Short_Position'] = df['Short_Position'][i-1]\n",
        "\n",
        "  return df\n",
        "\n",
        "def STO_model_results(df, date_index, initial_capital = 100):\n",
        "  df_evaluation = df[OHLC_features + targets2].copy(deep=True)\n",
        "  df_evaluation['%K'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=n_ind, smooth1=n_ind, smooth2=n_ind, fillna=False).stochrsi_k()*100\n",
        "  df_evaluation['%D'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=n_ind, smooth1=n_ind, smooth2=n_ind, fillna=False).stochrsi_d()*100\n",
        "  df_evaluation = df_evaluation[test_date[0]:test_date[-1]]\n",
        "\n",
        "  # thrs_range = np.linspace(10, 90, 9)\n",
        "  # thrs_range_l_opn = thrs_range\n",
        "  # thrs_range_l_cls = thrs_range\n",
        "  # thrs_range_s_opn = thrs_range\n",
        "  # thrs_range_s_cls = thrs_range\n",
        "  thrs_range_l_opn = [20]\n",
        "  thrs_range_l_cls = [80]\n",
        "  thrs_range_s_opn = [80]\n",
        "  thrs_range_s_cls = [20]\n",
        "\n",
        "  # Long\n",
        "  df_thrs_l = []\n",
        "  for thrs_l_opn in thrs_range_l_opn:\n",
        "    for thrs_l_cls in thrs_range_l_cls:\n",
        "      df_evaluation_thrs = STO_strategy(df_evaluation, thrs_l = [thrs_l_opn, thrs_l_cls], thrs_s = [np.nan, np.nan])\n",
        "      backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      df_thrs_l.append([thrs_l_opn, thrs_l_cls, np.nan, np.nan] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_l = pd.DataFrame(data = df_thrs_l, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "  df_thrs_l = df_thrs_l.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # Short\n",
        "  df_thrs_s = []\n",
        "  for thrs_s_opn in thrs_range_s_opn:\n",
        "    for thrs_s_cls in thrs_range_s_cls:\n",
        "      df_evaluation_thrs = STO_strategy(df_evaluation, thrs_l = [np.nan, np.nan], thrs_s = [thrs_s_opn, thrs_s_cls])\n",
        "      backtest_thrs = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "      df_thrs_s.append([np.nan, np.nan, thrs_s_opn, thrs_s_cls] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_thrs_s = pd.DataFrame(data = df_thrs_s, columns=['thrs_l_opn', 'thrs_l_cls', 'thrs_s_opn', 'thrs_s_cls', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "\n",
        "\n",
        "  df_thrs_s = df_thrs_s.sort_values(by=['roi'], ascending=False).reset_index(drop=True)\n",
        "\n",
        "  # # Backtest report\n",
        "  thrs_report = {'backtest_opt_l': {'thrs_l':[df_thrs_l['thrs_l_opn'][0], df_thrs_l['thrs_l_cls'][0]], 'thrs_s':[np.nan, np.nan]},\n",
        "                 'backtest_opt_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[df_thrs_s['thrs_s_opn'][0], df_thrs_s['thrs_s_cls'][0]]},\n",
        "                 'backtest_0_l': {'thrs_l':[20, 80], 'thrs_s':[np.nan, np.nan]}, # normal trigger point for STO strategy = 20/80\n",
        "                 'backtest_0_s': {'thrs_l':[np.nan, np.nan], 'thrs_s':[80, 20]} # normal trigger point for STO strategy = 20/80\n",
        "                }\n",
        "\n",
        "  backtest_result = {}\n",
        "  df_backtest_result = []\n",
        "\n",
        "  for k, v in thrs_report.items():\n",
        "    df_evaluation_thrs = STO_strategy(df_evaluation, thrs_l = [v['thrs_l'][0], v['thrs_l'][1]], thrs_s = [v['thrs_s'][0], v['thrs_s'][1]])\n",
        "    backtest_evaluation = Backtest(df_evaluation_thrs, df_evaluation_thrs.index[0], df_evaluation_thrs.index[-1], col_name = None, initial_capital = initial_capital, trd_fee_frac = trd_fee_frac, hld_fee_frac_hr = hld_fee_frac_hr)\n",
        "    backtest_result[k] = {'df': df_evaluation_thrs.copy(deep=True),\n",
        "                          'backtest': backtest_evaluation.copy()}\n",
        "    df_backtest_result.append([k] + report_summary(backtest_thrs, print_report = False, return_list = True))\n",
        "\n",
        "  df_backtest_result = pd.DataFrame(data = df_backtest_result, columns=['name', \n",
        "                                                'start', 'end', 'dur', 'init_capital', 'final_capital', 'roi', 'roi_ann', 'volatility_ann', 'sharpe_ratio_ann', \n",
        "                                                'port_mdd', 'trade_mdd', 'trade_P10_mdd', 'win_rate', 'no_trades', 'avg_hld_dur', 'max_hld_dur', 'reward_to_risk', 'expectency'])\n",
        "  return df_thrs_l, df_thrs_s, backtest_result, df_backtest_result\n",
        "\n",
        "# create strategy\n",
        "def STO_strategy(df,  thrs_l = [0, 0], # [Open (>=) , Close (<=)]\n",
        "                             thrs_s = [0, 0], signal = '%K', signal2 = '%D'):   # [Open (<=) , Close (>=)]\n",
        "  df['thrs_l_opn'] = thrs_l[0]\n",
        "  df['thrs_l_cls'] = thrs_l[1]\n",
        "  df['thrs_s_opn'] = thrs_s[0]\n",
        "  df['thrs_s_cls'] = thrs_s[1]\n",
        "\n",
        "  df['Long_Position'] = np.nan\n",
        "  df['Long_Price'] = np.nan\n",
        "  df['Short_Position'] = np.nan\n",
        "  df['Short_Price'] = np.nan\n",
        "\n",
        "  for i in range(len(df)):\n",
        "    idx = df.index[i]\n",
        "    # long position =======\n",
        "    if i == 0: \n",
        "      df.loc[idx, 'Long_Position'] = 0\n",
        "      pass\n",
        "\n",
        "    elif df[signal2][i] <= df['thrs_l_opn'][i] and df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]: # %D <= thres , %K cross %D upward\n",
        "      # trigger open long position\n",
        "      df.loc[idx, 'Long_Position'] = 1\n",
        "      df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "\n",
        "    elif (df[signal2][i] >= df['thrs_l_cls'][i] and df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]) or i == len(df) - 1: # %D >= thres , %K cross %D downward\n",
        "      # trigger close long position \n",
        "      df.loc[idx, 'Long_Position'] = 0\n",
        "      df.loc[idx, 'Long_Price'] = df['Close'][i]\n",
        "    \n",
        "    else:\n",
        "      # do nothing (continue last position)\n",
        "      df.loc[idx, 'Long_Position'] = df['Long_Position'][i-1]\n",
        "\n",
        "\n",
        "    # short position =======\n",
        "    if i == 0: \n",
        "      df.loc[idx, 'Short_Position'] = 0\n",
        "\n",
        "    elif df[signal2][i] >= df['thrs_s_cls'][i] and df[signal][i-1] > df[signal2][i-1] and df[signal][i] <= df[signal2][i]: # %D >= thres , %K cross %D downward\n",
        "      # trigger open short position\n",
        "      df.loc[idx, 'Short_Position'] = 1\n",
        "      df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "\n",
        "    elif (df[signal2][i] <= df['thrs_s_opn'][i] and df[signal][i-1] < df[signal2][i-1] and df[signal][i] >= df[signal2][i]) or i == len(df) - 1: # %D <= thres , %K cross %D upward\n",
        "      # trigger close short position \n",
        "      df.loc[idx, 'Short_Position'] = 0\n",
        "      df.loc[idx, 'Short_Price'] = df['Close'][i]\n",
        "    \n",
        "    else:\n",
        "      # do nothing (continue last position)\n",
        "      df.loc[idx, 'Short_Position'] = df['Short_Position'][i-1]\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yt3VBxM62k7U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb8olAB7u0KX"
      },
      "source": [
        "# Backtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYU2dLfkXbsy"
      },
      "outputs": [],
      "source": [
        "# get_backtest_result(X_2020, date_list_2020, original_df, scaler_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAl339VE5RF1"
      },
      "outputs": [],
      "source": [
        "# print(\"2020\")\n",
        "# get_backtest_result(X_2020, date_list_2020, original_df, scaler_label)\n",
        "# print(\"2021\")\n",
        "# get_backtest_result(X_2021, date_list_2021, original_df, scaler_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfRy0jTT5Stx"
      },
      "outputs": [],
      "source": [
        "# date_2021 = np.array(date_2021).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETUHrY_1ZDWl"
      },
      "outputs": [],
      "source": [
        "# X = X_2020\n",
        "# date_list = date_list_2020\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_hfXQL9ZDaz"
      },
      "outputs": [],
      "source": [
        "# y_pred = model.predict(X)\n",
        "# train_data_filtered = original_df[pd.to_datetime(original_df['Time']).isin(date_list)].copy()\n",
        "# train_data_filtered['predict'] = scaler_label.inverse_transform(y_pred).reshape(-1)\n",
        "\n",
        "# train_data_filtered['Time'] = pd.to_datetime(train_data_filtered['Time'])\n",
        "# temp_df =  train_data_filtered.copy()\n",
        "# temp_df = temp_df.set_index('Time')\n",
        "\n",
        "# test_date = date_list\n",
        "# print(\"Start back test\")\n",
        "# df_thrs_l_rsi, df_thrs_s_rsi, backtest_result_rsi, df_backtest_result_rsi = RSI_model_results(temp_df, test_date, initial_capital = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-mG9ZAZWFIU"
      },
      "outputs": [],
      "source": [
        "def get_backtest_result(model, X, y, date_list, original_df, scaler, scaler_label, feature_columns, target_columns, m):\n",
        "  y_pred = model.predict(X, verbose=0)\n",
        "\n",
        "  train_data_filtered = original_df[pd.to_datetime(original_df['Time']).isin(date_list)].copy()\n",
        "  train_data_filtered['predict_1'] = scaler_label.inverse_transform(y_pred).reshape(-1)\n",
        "\n",
        "  train_data_filtered['Time'] = pd.to_datetime(train_data_filtered['Time'])\n",
        "  temp_df =  train_data_filtered.copy()\n",
        "  temp_df = temp_df.set_index('Time')\n",
        "  # global test_date\n",
        "  # test_date = date_list\n",
        "\n",
        "  temp_df['buy'] = np.nan\n",
        "  temp_df['sell'] = np.nan\n",
        "  temp_df['hold'] = np.nan\n",
        "  temp_df['port'] = np.nan\n",
        "\n",
        "  score,temp, m = trade_by_model(temp_df.reset_index(), m)\n",
        "\n",
        "  # print(\"#\"*50)\n",
        "  # print(\"SCORE BACK TEST:\")\n",
        "  # print('BH', roi_bh)\n",
        "  # print('MACD', roi_macd)\n",
        "  # print('RSI', roi_rsi)\n",
        "  # print('SMA', roi_sma)\n",
        "  # print('STO', roi_sto)\n",
        "  # print(\"MODEL\", score)\n",
        "  loss, mse = model.evaluate(X, y, verbose=0)\n",
        "  data = {\n",
        "    # 'BH':[roi_bh],\n",
        "    # 'MACD':[roi_macd],\n",
        "    # 'RSI':[roi_rsi],\n",
        "    # 'SMA':[roi_sma],\n",
        "    # 'STO':[roi_sto],\n",
        "    'ROI_MODEL': [score],\n",
        "    'lOSS':[loss],\n",
        "    'MSE':[mse]\n",
        "  } \n",
        "  return data, temp, m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXPbqMDkWvGR"
      },
      "outputs": [],
      "source": [
        "# data = {\n",
        "#     'BH':[roi_bh],\n",
        "#     'MACD':[roi_macd],\n",
        "#     'RSI':[roi_rsi],\n",
        "#     'SMA':[roi_sma],\n",
        "#     'STO':[roi_sto],\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl3bfqKqWqgn"
      },
      "outputs": [],
      "source": [
        "# y_pred = model.predict(X_test)\n",
        "# train_data_filtered = original_df[pd.to_datetime(original_df['Time']).isin(test_date)].copy()\n",
        "# train_data_filtered['predict'] = scaler_label.inverse_transform(y_pred).reshape(-1)\n",
        "\n",
        "# train_data_filtered['Time'] = pd.to_datetime(train_data_filtered['Time'])\n",
        "# temp_df =  train_data_filtered.copy()\n",
        "# temp_df = temp_df.set_index('Time')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZRtJY5N0za0"
      },
      "outputs": [],
      "source": [
        "# temp_df[feature_columns] = scaler.inverse_transform(temp_df[feature_columns])\n",
        "# temp_df[target_columns] = scaler_label.inverse_transform(temp_df[target_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seqBXshq5-sp"
      },
      "outputs": [],
      "source": [
        "# test_date = date_2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gx6NnGYu1zn"
      },
      "outputs": [],
      "source": [
        "# df_thrs_l_rsi, df_thrs_s_rsi, backtest_result_rsi, df_backtest_result_rsi = RSI_model_results(temp_df, test_date, initial_capital = 100)\n",
        "# df_thrs_l_bh, df_thrs_s_bh, backtest_result_bh, df_backtest_result_bh = BH_model_results(temp_df, test_date, initial_capital = 100)\n",
        "# df_thrs_l_macd, df_thrs_s_macd, backtest_result_macd, df_backtest_result_macd = MACD_model_results(temp_df, test_date, initial_capital = 100)\n",
        "# df_thrs_l_sma, df_thrs_s_sma, backtest_result_sma, df_backtest_result_sma = SMA_model_results(temp_df, test_date, initial_capital = 100)\n",
        "# df_thrs_l_sto, df_thrs_s_sto, backtest_result_sto, df_backtest_result_sto = STO_model_results(temp_df, test_date, initial_capital = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1jAlFxo6CTP"
      },
      "outputs": [],
      "source": [
        "# roi_list = list()\n",
        "# roi_rsi = df_thrs_l_rsi['roi'].values[0]\n",
        "# roi_list.append(roi_rsi)\n",
        "# roi_bh = df_thrs_l_bh['roi'].values[0]\n",
        "# roi_list.append(roi_bh)\n",
        "# roi_macd = df_thrs_l_macd['roi'].values[0]\n",
        "# roi_list.append(roi_macd)\n",
        "# roi_sma = df_thrs_l_sma['roi'].values[0]\n",
        "# roi_list.append(roi_sma)\n",
        "# roi_sto = df_thrs_l_sto['roi'].values[0]\n",
        "# roi_list.append(roi_sto)\n",
        "# roi_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wbAqHJ2vAKT"
      },
      "outputs": [],
      "source": [
        "# roi_list = list()\n",
        "# roi_rsi = df_thrs_l_rsi['roi'].values[0]\n",
        "# roi_list.append(roi_rsi)\n",
        "# roi_bh = df_thrs_l_bh['roi'].values[0]\n",
        "# roi_list.append(roi_bh)\n",
        "# roi_macd = df_thrs_l_macd['roi'].values[0]\n",
        "# roi_list.append(roi_macd)\n",
        "# roi_sma = df_thrs_l_sma['roi'].values[0]\n",
        "# roi_list.append(roi_sma)\n",
        "# roi_sto = df_thrs_l_sto['roi'].values[0]\n",
        "# roi_list.append(roi_sto)\n",
        "# roi_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8hUU-1r1SkM"
      },
      "outputs": [],
      "source": [
        "# X_train = []\n",
        "# train_date = []\n",
        "# for i in range(temp_df[target_columns].shape[0] - (T-1)):\n",
        "#   train_date.append(temp_df[['Time']].iloc[i + (T-1)].values)\n",
        "#   X_train.append(temp_df[feature_columns].iloc[i:i+T].values)\n",
        "#   # y_train.append(train_data[target_columns].iloc[i + (T-1)].values)\n",
        "# X_train = np.array(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1lETv6j24UT"
      },
      "outputs": [],
      "source": [
        "# train_date = np.array(train_date).reshape(-1)\n",
        "# val_date = np.array(val_date).reshape(-1)\n",
        "# test_date = np.array(test_date).reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8TM8BT02hLo"
      },
      "outputs": [],
      "source": [
        "# temp_df = temp_df[temp_df['Time'].isin(train_date)].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slC5QZDA4Eeu"
      },
      "outputs": [],
      "source": [
        "# len(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ-buzPQ0sZ-"
      },
      "outputs": [],
      "source": [
        "# BATCH = 128\n",
        "# y_pred = model.predict(X_train)\n",
        "\n",
        "# # temp_df = temp_df[temp_df['Time'].isin(train_date)].copy()\n",
        "# # temp_df['predict'] = scaler_label.inverse_transform(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YmBsJJNvKNz"
      },
      "outputs": [],
      "source": [
        "# temp_df['buy'] = np.nan\n",
        "# temp_df['sell'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnHykOR7vSYN"
      },
      "outputs": [],
      "source": [
        "# score,temp = trade_by_model(temp_df.reset_index())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRJ9ozDovddy"
      },
      "outputs": [],
      "source": [
        "# import seaborn as sns\n",
        "# sns.set(rc={'figure.figsize':(11.7,8.27)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LrekdCgvUlR"
      },
      "outputs": [],
      "source": [
        "# plot_training_result(original_df, test_date, X_test, y_test, scaler_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P04ryS7vX7l"
      },
      "outputs": [],
      "source": [
        "# buy = temp.query(\"buy == 1\")\n",
        "# sell = temp.query(\"sell == 1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvD4uFmD6N2D"
      },
      "outputs": [],
      "source": [
        "# plt.plot(temp['Time'], temp['Close'])\n",
        "# plt.scatter(buy['Time'],buy['Close'], c='green')\n",
        "# plt.scatter(sell['Time'],sell['Close'], c='red')\n",
        "# plt.figure()\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(temp['Time'], temp['predict'])\n",
        "# plt.figure()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb6K-v1_6PNl"
      },
      "outputs": [],
      "source": [
        "# session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "# sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
        "# tf.compat.v1.keras.backend.set_session(sess)\n",
        "# df = pd.read_csv(\"/content/gdrive/MyDrive/2022/data_set_day.csv\")\n",
        "# df['Time'] = pd.to_datetime(df['Time']).dt.strftime(\"%Y-%m-%d 00:00:00\")\n",
        "# df = df.drop(columns=['index'])\n",
        "# result = pd.DataFrame()\n",
        "# for i in ['AMD', 'GOOGL', 'NVDA', 'OXY', 'SQQQ', 'TQQQ', 'TSLA']:\n",
        "#   df2 = df[df['Stock'] == i].copy()\n",
        "#   score = main(df2)\n",
        "#   score['STOCK'] = i\n",
        "#   result = pd.concat([result, score], axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkNE5rRuok53"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx_Ml_qvtfOT"
      },
      "source": [
        "# Prep data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRbxAP7XtlN3"
      },
      "outputs": [],
      "source": [
        "def df_extract_feature(df, rolling_indicator = False):\n",
        "  df['Rel_Open'] = (df['Open'] - df['Close'])/df['Close']\n",
        "  df['Rel_High'] = (df['High'] - df['Close'])/df['Close']\n",
        "  df['Rel_Low'] = (df['Low'] - df['Close'])/df['Close']\n",
        "\n",
        "  # Create Indicator Column\n",
        "\n",
        "  # SMA\n",
        "  df['Rel_SMA_fast'] = (ta.trend.SMAIndicator(close=df['Close'], window=n_ind, fillna=False).sma_indicator() - df['Close']) / df['Close'] \n",
        "  df['Rel_SMA_slow'] = (ta.trend.SMAIndicator(close=df['Close'], window=k_ind, fillna=False).sma_indicator() - df['Close']) / df['Close'] \n",
        "\n",
        "  # CCI\n",
        "  df['CCI'] = ta.trend.CCIIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=n_ind, constant=0.015, fillna=False).cci()\n",
        "\n",
        "  # ROC\n",
        "  df['ROC'] = ta.momentum.ROCIndicator(close=df['Close'], window=n_ind, fillna=False).roc()\n",
        "\n",
        "  # %R\n",
        "  df['%R'] = ta.momentum.WilliamsRIndicator(high=df['High'], low=df['Low'], close=df['Close'], lbp=n_ind, fillna=False).williams_r()\n",
        "\n",
        "  # MFI\n",
        "  df['MFI'] = ta.volume.MFIIndicator(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], window=n_ind, fillna=False).money_flow_index()\n",
        "\n",
        "  # VPT\n",
        "  df['VPT'] = ta.volume.VolumePriceTrendIndicator(close=df['Close'], volume=df['Volume'], fillna=False).volume_price_trend()\n",
        "  df.loc[df.index[0], 'VPT'] = np.nan\n",
        "  df.loc[df.index[1], 'VPT'] = np.nan = np.nan # correct library bug. the first 2 row in VPT should be np.nan\n",
        "\n",
        "  # VWAP\n",
        "  df['VWAP'] = (ta.volume.VolumeWeightedAveragePrice(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], window=n_ind, fillna=False).volume_weighted_average_price()- df['Close']) / df['Close']\n",
        "\n",
        "  # MACD\n",
        "  df['MACD'] = ta.trend.macd(close=df['Close'], window_slow=k_ind, window_fast=n_ind, fillna=False)\n",
        "\n",
        "  # ADX # create warning but the results are correct\n",
        "  # warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
        "  df['ADX'] = ta.trend.ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=n_ind, fillna=False).adx()\n",
        "  # warnings.filterwarnings('default', category=RuntimeWarning)\n",
        "\n",
        "  # RSI\n",
        "  df['RSI'] = ta.momentum.RSIIndicator(close=df['Close'], window=n_ind, fillna=False).rsi()\n",
        "\n",
        "  # TSI\n",
        "  df['TSI'] = ta.momentum.TSIIndicator(close=df['Close'], window_slow=k_ind, window_fast=n_ind, fillna=False).tsi()\n",
        "\n",
        "  # %K\n",
        "  df['%K'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=n_ind, smooth1=n_ind, smooth2=n_ind, fillna=False).stochrsi_k()\n",
        "\n",
        "  # %D\n",
        "  df['%D'] = ta.momentum.StochRSIIndicator(close=df['Close'], window=n_ind, smooth1=n_ind, smooth2=n_ind, fillna=False).stochrsi_d()\n",
        "\n",
        "  # Bollinger Bands\n",
        "  df['Rel_BB_hband'] = (ta.volatility.BollingerBands(close=df['Close'], window=n_ind, window_dev=2, fillna=False).bollinger_hband() - df['Close']) / df['Close']\n",
        "  df['Rel_BB_lband'] = (ta.volatility.BollingerBands(close=df['Close'], window=n_ind, window_dev=2, fillna=False).bollinger_lband() - df['Close']) / df['Close']\n",
        "\n",
        "  # ATR\n",
        "  df['Rel_ATR'] = ta.volatility.AverageTrueRange(high=df['High'], low=df['Low'], close=df['Close'], window=n_ind, fillna=False).average_true_range() / df['Close']\n",
        "\n",
        "  # UI\n",
        "  df['UI'] = ta.volatility.UlcerIndex(close=df['Close'], window=n_ind, fillna=False).ulcer_index()\n",
        "\n",
        "  #ADI (Accumulation/Distribution Index)\n",
        "  # df['ADI'] = ta.volume.AccDistIndexIndicator(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], fillna=True).acc_dist_index()\n",
        "\n",
        "  # # # OBV\n",
        "  # df['OBV'] = ta.volume.OnBalanceVolumeIndicator(close=df['Close'], volume=df['Volume'], fillna=False).on_balance_volume()\n",
        "\n",
        "  # CMF\n",
        "  df['CMF'] = ta.volume.ChaikinMoneyFlowIndicator(high=df['High'], low=df['Low'], close=df['Close'], volume=df['Volume'], window=n_ind, fillna=False).chaikin_money_flow()\n",
        "\n",
        "  # FI \n",
        "  df['FI'] = ta.volume.ForceIndexIndicator(close=df['Close'], volume=df['Volume'], window=n_ind, fillna=False).force_index()\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO59xJIzULyu"
      },
      "outputs": [],
      "source": [
        "def Xy4nn(df, feature_columns, target_columns, T):\n",
        "  X, y = [], []\n",
        "  date_list = []\n",
        "  for i in range(df[target_columns].shape[0] - (T-1)):\n",
        "    date_list.append(df[['Time']].iloc[i + (T-1)].values)\n",
        "    X.append(df[feature_columns].iloc[i:i+T].values)\n",
        "    y.append(df[target_columns].iloc[i + (T-1)].values)\n",
        "\n",
        "  X, y = np.array(X), np.array(y).reshape(-1,len(target_columns))\n",
        "  return X, y, date_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEmf9uuXT5Aw"
      },
      "outputs": [],
      "source": [
        "def main(df, TEST_YEAR):\n",
        "  df['label_1'] = df['Close'].pct_change(1).shift(periods=-1)\n",
        "  df = df_extract_feature(df)\n",
        "  df = df.dropna()\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler_label = MinMaxScaler()\n",
        "\n",
        "  feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume', \n",
        "        'Rel_Open', 'Rel_High', 'Rel_Low', 'Rel_SMA_fast', 'Rel_SMA_slow',\n",
        "        'CCI', 'ROC', '%R', 'MFI', 'VPT', 'VWAP', 'MACD', 'ADX', 'RSI', 'TSI',\n",
        "        '%K', '%D', 'Rel_BB_hband', 'Rel_BB_lband', 'Rel_ATR', 'UI', 'CMF',\n",
        "        'FI']\n",
        "\n",
        "  target_columns = ['label_1']\n",
        "\n",
        "  original_df = df.copy()\n",
        "\n",
        "  # TEST_YEAR = 2021\n",
        "  TRAIN_YEAR = TEST_YEAR - 6\n",
        "  VALID_YEAR = TEST_YEAR - 1\n",
        "\n",
        "  print(\"Train:\", TRAIN_YEAR, '-', VALID_YEAR - 1)\n",
        "  print(\"Valid:\", VALID_YEAR)\n",
        "  print(\"Test:\", TEST_YEAR)\n",
        "\n",
        "  train_data = df[(df['year'] >= TRAIN_YEAR) & (df['year'] < VALID_YEAR)].copy()\n",
        "  val_data = df[df['year'] == VALID_YEAR].copy()\n",
        "  test_data = df[df['year'] == TEST_YEAR].copy()\n",
        "\n",
        "  train_data[feature_columns] = scaler.fit_transform(train_data[feature_columns])\n",
        "  train_data[target_columns] = scaler_label.fit_transform(train_data[target_columns])\n",
        "\n",
        "  val_data[feature_columns] = scaler.transform(val_data[feature_columns])\n",
        "  val_data[target_columns] = scaler_label.transform(val_data[target_columns])\n",
        "\n",
        "  test_data[feature_columns] = scaler.transform(test_data[feature_columns])\n",
        "  test_data[target_columns] = scaler_label.transform(test_data[target_columns])\n",
        "\n",
        "  X_train, y_train, train_date = Xy4nn(train_data, feature_columns, target_columns, T)\n",
        "  X_val, y_val, val_date = Xy4nn(val_data, feature_columns, target_columns, T)\n",
        "  X_test, y_test, test_date = Xy4nn(test_data, feature_columns, target_columns, T)\n",
        "\n",
        "  train_date = np.array(train_date).reshape(-1)\n",
        "  val_date = np.array(val_date).reshape(-1)\n",
        "  test_data_date = np.array(test_date).reshape(-1)\n",
        "\n",
        "  N = X_train.shape[2]\n",
        "\n",
        "  BATCH = 128\n",
        "  EPOCH = 100                           # number of epochs\n",
        "  LR = 1e-7\n",
        "\n",
        "  lstm_no_node_list = [64, 128, 256]\n",
        "  cnn_no_node_list = [64, 128, 256]\n",
        "  kernel_size_list = [7]\n",
        "\n",
        "  max_profit = 0\n",
        "  result_summary = pd.DataFrame()\n",
        "  for cnn_no_node, lstm_no_node, kernel_size in list(list(itertools.product(cnn_no_node_list, lstm_no_node_list, kernel_size_list))):\n",
        "\n",
        "    input1 = Input(shape=(T,N))\n",
        "    # x = Conv1D(filters=cnn_no_node, kernel_size=kernel_size, strides=1, padding='same', activation='relu')(input1)\n",
        "    # x = LSTM(lstm_no_node, return_sequences=True)(x)\n",
        "    x = LSTM(lstm_no_node, return_sequences=True)(input1)\n",
        "    x = Conv1D(filters=cnn_no_node, kernel_size=kernel_size, strides=1, padding='same', activation='relu')(x)\n",
        "    # x = LSTM(lstm_no_node, return_sequences=True)(input1)\n",
        "    x = Dropout(0.6)(x)\n",
        "    # x = LSTM(lstm_no_node, return_sequences=True)(x)\n",
        "    # x = Dropout(0.4)(x)\n",
        "    x = Flatten()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(64)(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    out1 = Dense(1, activation='sigmoid', name='class1')(x)\n",
        "\n",
        "\n",
        "    model = Model(inputs=input1, outputs=[out1])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=LR),\n",
        "                loss='MeanSquaredError',\n",
        "                metrics='MeanSquaredError')\n",
        "    try:\n",
        "      model.load_weights('model.h5')\n",
        "    except:\n",
        "      pass\n",
        "    model.save_weights('model.h5')\n",
        "\n",
        "    # model.summary()\n",
        "    K.set_value(model.optimizer.lr, LR)\n",
        "\n",
        "    d_k = 256\n",
        "    d_v = 256\n",
        "    n_heads = 12\n",
        "    ff_dim = 256\n",
        "    lr_decay = ReduceLROnPlateau(monitor='val_loss',                 \n",
        "                                patience=10, verbose=0, \n",
        "                                factor=0.95, min_lr=1e-3, cooldown=0)  \n",
        "    # Define Early Stopping:\n",
        "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0,\n",
        "                              patience=30, verbose=0, mode='auto',\n",
        "                              baseline=None, restore_best_weights=True)\n",
        "\n",
        "    History = model.fit(X_train, y_train,\n",
        "                          epochs=EPOCH,\n",
        "                          batch_size=BATCH,\n",
        "                          validation_split=0.0,\n",
        "                          validation_data=(X_val, y_val),\n",
        "                          shuffle=True, verbose=0,\n",
        "                          callbacks=[lr_decay, early_stop])\n",
        "    \n",
        "    result = dict()\n",
        "    result_train = get_backtest_result(model, X_train, y_train, train_date, original_df, scaler, scaler_label, feature_columns, target_columns)\n",
        "    result_val = get_backtest_result(model, X_val, y_val, val_date, original_df, scaler, scaler_label, feature_columns, target_columns)\n",
        "    result_test = get_backtest_result(model, X_test, y_test, test_data_date, original_df, scaler, scaler_label, feature_columns, target_columns)\n",
        "\n",
        "    result_data = {\n",
        "        'train':result_train['MODEL'],\n",
        "        'valid':result_val['MODEL'],\n",
        "        'test':result_test['MODEL'],\n",
        "        'train_mse':result_train['MSE'],\n",
        "        'valid_mse':result_val['MSE'],\n",
        "        'test_mse':result_test['MSE'],\n",
        "    }\n",
        "    result = pd.DataFrame(result_data)\n",
        "\n",
        "    result['cnn_node'] = cnn_no_node\n",
        "    result['lstm_no_node'] = lstm_no_node\n",
        "    result['kernal_size'] = kernel_size\n",
        "    result_summary = pd.concat([result_summary, result])\n",
        "  return result_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcDmBBObu3JD"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "from itertools import permutations\n",
        "from keras.utils.vis_utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def df_identifying_label(df, span):\n",
        "  df['Smoothed_Price*'] = smooth_data_savgol_2(np.array(df['Close']), span)\n",
        "  # df['Smoothed_Price*'] = smooth_data_savgol_2(np.array(df['Smoothed_Price*']), span)\n",
        "  # df['Smoothed_Price*'] = smooth_data_savgol_2(np.array(df['Smoothed_Price*']), span)\n",
        "  df['Smoothed_Return*'] = df['Smoothed_Price*'].pct_change(1).shift(periods=-1)\n",
        "  return df\n",
        "\n",
        "def smooth_data_savgol_2(arr, span):  \n",
        "    return savgol_filter(arr, span * 2 + 1, 1)"
      ],
      "metadata": {
        "id": "XEXdsWwXgjXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from keras.layers import Bidirectional"
      ],
      "metadata": {
        "id": "1Gz6zjoeDKBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTftQ7Yk2k40"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sandbox"
      ],
      "metadata": {
        "id": "2-WJQLQcm5T7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "\n",
        "  input1 = Input(shape=(32,28))\n",
        "  lstm_hp_units = hp.Int('lstm_units', min_value=32, max_value=256, step=32)\n",
        "  cnn_hp_units = hp.Int('cnn_units', min_value=32, max_value=256, step=32)\n",
        "  kernel_size_list = hp.Int('kernal_units', min_value=3, max_value=9, step=1)\n",
        "  drop_out_hp_units = hp.Choice('drop_out_units', values=[0.3, 0.35 ,0.4 ,0.45])\n",
        "  # x = Bidirectional(LSTM(lstm_hp_units, return_sequences=True, activation='relu'))(input1)\n",
        "  # x = Dropout(drop_out_hp_units)(x)\n",
        "  # x = Bidirectional(LSTM(lstm_hp_units, return_sequences=True))(x)\n",
        "  # x = Dropout(drop_out_hp_units)(x)\n",
        "  x = LSTM(lstm_hp_units, return_sequences=True, activation='relu')(input1)\n",
        "  x = Dropout(drop_out_hp_units)(x)\n",
        "  # x = LSTM(lstm_hp_units, return_sequences=True)(x)\n",
        "  # x = Dropout(drop_out_hp_units)(x)\n",
        "  x = Conv1D(filters=cnn_hp_units, kernel_size=kernel_size_list, activation='relu')(x)\n",
        "  x = Dropout(drop_out_hp_units)(x)\n",
        "  # x = LSTM(lstm_no_node, return_sequences=True)(x)\n",
        "  # x = Dropout(0.4)(x)\n",
        "  x = Flatten()(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  dense_list = hp.Int('dense_units', min_value=32, max_value=128, step=32)\n",
        "  x = Dense(dense_list)(x)\n",
        "  x = Dropout(drop_out_hp_units)(x)\n",
        "  out1 = Dense(1, activation='sigmoid', name='class1')(x)\n",
        "\n",
        "  # model = keras.Sequential()\n",
        "  # model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "  # # Tune the number of units in the first Dense layer\n",
        "  # # Choose an optimal value between 32-512\n",
        "  # hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  # model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  # model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])#, 1e-5, 1e-6, 1e-7, 1e-8])#, 1e-5, 1e-6, 1e-7, 1e-8])\n",
        "  model = Model(inputs=input1, outputs=[out1])\n",
        "\n",
        "  model.compile(#optimizer='SGD',\n",
        "                Adam(learning_rate=hp_learning_rate),\n",
        "            loss='MeanSquaredError',\n",
        "            metrics='MeanSquaredError')#[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  # model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "  #               loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  #               metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "8ocBmwcZCibw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(df, TEST_YEAR):\n",
        "# df = df[df['Stock'] == 'AMD'].copy()\n",
        "  df['year'] = pd.to_datetime(df['Time']).dt.year\n",
        "  # df = df[df['year'].isin([2018, 2019, 2020, 2021])].copy()\n",
        "\n",
        "  df['label_1'] = df['Close'].pct_change(1).shift(periods=-1)\n",
        "  # df = df_identifying_label(df, 5)\n",
        "  df = df_extract_feature(df)\n",
        "  df = df.dropna()\n",
        "  df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler_label = MinMaxScaler()\n",
        "\n",
        "  feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume', \n",
        "        'Rel_Open', 'Rel_High', 'Rel_Low', 'Rel_SMA_fast', 'Rel_SMA_slow',\n",
        "        'CCI', 'ROC', '%R', 'MFI', 'VPT', 'VWAP', 'MACD', 'ADX', 'RSI', 'TSI',\n",
        "        '%K', '%D', 'Rel_BB_hband', 'Rel_BB_lband', 'Rel_ATR', 'UI', 'CMF',\n",
        "        'FI']\n",
        "\n",
        "  target_columns = ['label_1']\n",
        "\n",
        "  original_df = df.copy()\n",
        "  df['month'] = pd.to_datetime(df['Time']).dt.month\n",
        "\n",
        "  # TEST_YEAR = 2021\n",
        "  TRAIN_YEAR = TEST_YEAR - 2\n",
        "  VALID_YEAR = TEST_YEAR - 1\n",
        "\n",
        "  print(\"Train:\", TRAIN_YEAR, '-', VALID_YEAR - 1)\n",
        "  print(\"Valid:\", VALID_YEAR)\n",
        "  print(\"Test:\", TEST_YEAR)\n",
        "\n",
        "  # train_data = df[(df['year'] >= TRAIN_YEAR) & (df['year'] < VALID_YEAR)].copy()\n",
        "  # val_data = df[df['year'] == VALID_YEAR].copy()\n",
        "  test_data = df[df['year'] == TEST_YEAR].copy()\n",
        "\n",
        "  # print(train_data.shape[0])\n",
        "  # print(val_data.shape[0])\n",
        "  # print(test_data.shape[0])\n",
        "\n",
        "  # train_data[feature_columns] = scaler.fit_transform(train_data[feature_columns])\n",
        "  # train_data[target_columns] = scaler_label.fit_transform(train_data[target_columns])\n",
        "\n",
        "  # val_data[feature_columns] = scaler.transform(val_data[feature_columns])\n",
        "  # val_data[target_columns] = scaler_label.transform(val_data[target_columns])\n",
        "\n",
        "  # # # train_data = train_data.query(\"month == 11\").copy()\n",
        "  # # # val_data = val_data.query(\"month == 12\").copy()\n",
        "\n",
        "  # X_train, y_train, train_date = Xy4nn(train_data, feature_columns, target_columns, T)\n",
        "  # X_val, y_val, val_date = Xy4nn(val_data, feature_columns, target_columns, T)\n",
        "  X_test, y_test, test_date = Xy4nn(test_data, feature_columns, target_columns, T)\n",
        "  # #   test_data_date = np.array(test_date).reshape(-1)\n",
        "  # tuner = kt.Hyperband(model_builder,\n",
        "  #                     objective='val_loss',\n",
        "  #                     max_epochs=10,\n",
        "  #                     factor=3,\n",
        "  #                     directory='my_dir',\n",
        "  #                     project_name='intro_to_kt', overwrite=True)\n",
        "\n",
        "  # early_stop = EarlyStopping(monitor='val_loss', min_delta=0,\n",
        "  #                           patience=30, verbose=0, mode='auto',\n",
        "  #                           baseline=None, restore_best_weights=True)\n",
        "\n",
        "  # tuner.search(X_train, y_train, epochs=50, validation_split=0.0,  validation_data=(X_val, y_val), callbacks=[early_stop], batch_size=32)\n",
        "\n",
        "  # # Get the optimal hyperparameters\n",
        "  # best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "  # print(best_hps.get('dense_units'))\n",
        "  # print(best_hps.get('lstm_units'))\n",
        "  # print(best_hps.get('cnn_units'))\n",
        "\n",
        "  # # Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
        "  # model = tuner.hypermodel.build(best_hps)\n",
        "  # history = model.fit(X_train, y_train, epochs=50, validation_split=0.0,  validation_data=(X_val, y_val), batch_size=32)\n",
        "\n",
        "  # val_acc_per_epoch = history.history['val_loss']\n",
        "  # best_epoch = val_acc_per_epoch.index(min(val_acc_per_epoch)) + 1\n",
        "  # print('Best epoch: %d' % (best_epoch,))\n",
        "\n",
        "  # result = dict()\n",
        "  # train_date = np.array(train_date).reshape(-1)\n",
        "  # val_date = np.array(val_date).reshape(-1)\n",
        "  test_data_date = np.array(test_date).reshape(-1)\n",
        "\n",
        "  # result_train, temp_train, _ = get_backtest_result(model, X_train, y_train, train_date, original_df, scaler, scaler_label, feature_columns, target_columns, 100)\n",
        "  # result_val, temp_val, _ = get_backtest_result(model, X_val, y_val, val_date, original_df, scaler, scaler_label, feature_columns, target_columns, 100)\n",
        "  # result_test, temp_test, _ = get_backtest_result(model, X_test, y_test, test_data_date, original_df, scaler, scaler_label, feature_columns, target_columns, 100)\n",
        "\n",
        "  # result_data = {\n",
        "  #     'train':result_train['ROI_MODEL'],\n",
        "  #     'valid':result_val['ROI_MODEL'],\n",
        "  #     'test':result_test['ROI_MODEL'],\n",
        "  #     'train_mse':result_train['MSE'],\n",
        "  #     'valid_mse':result_val['MSE'],\n",
        "  #     'test_mse':result_test['MSE'],\n",
        "  # }\n",
        "  # result = pd.DataFrame(result_data)\n",
        "\n",
        "  # result['cnn_node'] = best_hps.get('cnn_units')\n",
        "  # result['lstm_no_node'] = best_hps.get('lstm_units')\n",
        "  # result['kernal_size'] = best_hps.get('kernal_units')\n",
        "  # result['drop_out'] = best_hps.get('drop_out_units')\n",
        "  # result_summary = pd.concat([result_summary, result])\n",
        "\n",
        "  # result_test_dict = dict()\n",
        "  # result_test_df_dict = dict()\n",
        "  # temp_m = dict()\n",
        "  # summary_df = pd.DataFrame()\n",
        "  m = {\n",
        "    'BH':[100],\n",
        "    'MACD':[100],\n",
        "    'RSI':[100],\n",
        "    'SMA':[100],\n",
        "    'STO':[100],\n",
        "  } \n",
        "  # for i in range(1,13,1):\n",
        "  #   test_data_temp = test_data.query(f\"month == {i}\").copy()\n",
        "  #   print(test_data_temp.shape[0])\n",
        "  #   X_test, y_test, test_date = Xy4nn(test_data_temp, feature_columns, target_columns, T)\n",
        "  #   test_data_date = np.array(test_date).reshape(-1)\n",
        "  result_m = get_backtest_technical_result(X_test, y_test, test_data_date, original_df, scaler, scaler_label, feature_columns, target_columns, m)\n",
        "  #   # result_test_dict[i] = result_test\n",
        "  #   # result_test_df_dict[i] = temp_test\n",
        "  tm = pd.DataFrame(result_m)\n",
        "  #   tm['month'] = i\n",
        "  #   # tm['port'] = m\n",
        "  #   summary_df = pd.concat([summary_df, tm])\n",
        "\n",
        "  # summary_df['YEAR'] = TEST_YEAR\n",
        "  # backtest_df['YEAR'] = TEST_YEAR\n",
        "  return tm#, backtest_df\n",
        "\n"
      ],
      "metadata": {
        "id": "jaZqOLTGnSEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_backtest_technical_result(X, y,date_list, original_df, scaler, scaler_label, feature_columns, target_columns, m):\n",
        "  # y_pred = model.predict(X, verbose=0)\n",
        "\n",
        "  train_data_filtered = original_df[pd.to_datetime(original_df['Time']).isin(date_list)].copy()\n",
        "  # train_data_filtered['predict_1'] = scaler_label.inverse_transform(y_pred).reshape(-1)\n",
        "  train_data_filtered['Time'] = pd.to_datetime(train_data_filtered['Time'])\n",
        "  temp_df =  train_data_filtered.copy()\n",
        "  temp_df = temp_df.set_index('Time')\n",
        "  global test_date\n",
        "  test_date = date_list\n",
        "\n",
        "  df_thrs_l_rsi, df_thrs_s_rsi, backtest_result_rsi, df_backtest_result_rsi = RSI_model_results(temp_df, test_date, initial_capital = float(m['RSI'][0]))\n",
        "  df_thrs_l_bh, df_thrs_s_bh, backtest_result_bh, df_backtest_result_bh = BH_model_results(temp_df, test_date, initial_capital = float(m['BH'][0]))\n",
        "  df_thrs_l_macd, df_thrs_s_macd, backtest_result_macd, df_backtest_result_macd = MACD_model_results(temp_df, test_date, initial_capital = float(m['MACD'][0]))\n",
        "  df_thrs_l_sma, df_thrs_s_sma, backtest_result_sma, df_backtest_result_sma = SMA_model_results(temp_df, test_date, initial_capital = float(m['SMA'][0]))\n",
        "  df_thrs_l_sto, df_thrs_s_sto, backtest_result_sto, df_backtest_result_sto = STO_model_results(temp_df, test_date, initial_capital = float(m['STO'][0]))\n",
        "  roi_list = list()\n",
        "  roi_rsi = df_thrs_l_rsi['final_capital'].values[0]\n",
        "  roi_list.append(roi_rsi)\n",
        "  roi_bh = df_thrs_l_bh['final_capital'].values[0]\n",
        "  roi_list.append(roi_bh)\n",
        "  roi_macd = df_thrs_l_macd['final_capital'].values[0]\n",
        "  roi_list.append(roi_macd)\n",
        "  roi_sma = df_thrs_l_sma['final_capital'].values[0]\n",
        "  roi_list.append(roi_sma)\n",
        "  roi_sto = df_thrs_l_sto['final_capital'].values[0]\n",
        "  roi_list.append(roi_sto)\n",
        "    # roi_list\n",
        "\n",
        "  data = {\n",
        "    'BH':[roi_bh],\n",
        "    'MACD':[roi_macd],\n",
        "    'RSI':[roi_rsi],\n",
        "    'SMA':[roi_sma],\n",
        "    'STO':[roi_sto],\n",
        "  } \n",
        "  return data"
      ],
      "metadata": {
        "id": "MzGdJs-4291d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/gdrive/MyDrive/2023/data_set_1hr_2023.csv\")\n",
        "\n",
        "#df['Time'] = pd.to_datetime(df['Time']).dt.strftime(\"%Y-%m-%d 00:00:00\")\n",
        "# df['year'] = pd.to_datetime(df['Time']).dt.year\n",
        "# df = df.drop(columns=['index'])\n",
        "result_train = pd.DataFrame()\n",
        "result_test = pd.DataFrame()\n",
        "# #'AMD', 'GOOGL', 'NVDA', 'OXY', #ABNB\n",
        "#for i in ['TQQQ', 'SQQQ', 'MRNA', 'APA', 'NFLX', 'MOS', 'AMD', 'NVDA','OXY', 'DVN', 'TSLA', 'GOOGL']:\n",
        "for i in ['ABNB']:\n",
        "  df2 = df[df['Stock'] == i].copy()\n",
        "  for TEST_YEAR in [2021, 2022]:\n",
        "    backtest_result_df = main(df2, TEST_YEAR)\n",
        "    backtest_result_df['STOCK'] = i\n",
        "    # test_result_df['STOCK'] = i\n",
        "    backtest_result_df['TEST_YEAR'] = TEST_YEAR\n",
        "    result_train = pd.concat([result_train, backtest_result_df], axis=0)\n",
        "    # result_test = pd.concat([result_test, test_result_df], axis=0)\n",
        "    result_train.to_csv(\"/content/gdrive/MyDrive/2023/1hr/lstm-cnn/backtest_result_model_ABNB.csv\", index=False)\n",
        "    # result_test.to_csv(\"/content/gdrive/MyDrive/2023/15min/lstm-cnn/backtest_result_test.csv\", index=False)"
      ],
      "metadata": {
        "id": "WOIGfVGRZmXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sdfsdfsdfsdfsdfsdfsd"
      ],
      "metadata": {
        "id": "SRWDRwliNncT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "27e26452-ff17-40c1-c132-b3ea442bcbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-72f91edd9926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msdfsdfsdfsdfsdfsdfsd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sdfsdfsdfsdfsdfsdfsd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gl27wcGCYPxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}